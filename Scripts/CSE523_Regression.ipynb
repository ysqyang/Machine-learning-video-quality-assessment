{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from decimal import Decimal\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier as ovr\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc, precision_score, recall_score, f1_score \n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dr = '~/Projects/video-qoe-labeling/new-data/Skype/'\n",
    "dtype = {'BitRate': np.float64, 'FreezeRatio': np.float64, 'Freezes': np.int32, 'Freezelength': np.float64, 'Quality': np.float64}\n",
    "df_reg = pd.read_table(dr + 'all-data.txt', delim_whitespace=True, dtype = dtype)\n",
    "df_reg['BitRate'] /= 100  # transforming BitRate to percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get (X, y) and set fold\n",
    "features = ['BitRate', 'FreezeRatio', 'Freezes', 'Freezelength']\n",
    "X, y = np.array(df_reg[features]), np.array(df_reg['Quality'])\n",
    "mse = {}\n",
    "mae = {}\n",
    "fold = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regressors = {'Random Forest': RandomForestRegressor(random_state = 1), \n",
    "               'Nearest Neighbors': KNeighborsRegressor(),\n",
    "               'SVM': SVR(),\n",
    "               'MLP': MLPRegressor(random_state = 1, max_iter = 10000),\n",
    "               'AdaBoost': AdaBoostRegressor(random_state = 1)\n",
    "              }\n",
    "\n",
    "params = {'Random Forest': {'n_estimators': range(1, 21), 'criterion': ('mse', 'mae')},\n",
    "          'Nearest Neighbors': {'n_neighbors':range(1, 11)},\n",
    "          'SVM': {'kernel':('poly', 'rbf', 'sigmoid'), 'C':[0.1, 1, 10]},\n",
    "          'MLP': {'hidden_layer_sizes': [(10,), (20,), (40,), (80,), (10,10), (20, 20), (40, 40), (80, 80)], \n",
    "                  'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "                  'activation': ('logistic', 'tanh', 'relu'), \n",
    "                  'solver': ('lbfgs', 'sgd', 'adam')},\n",
    "          'AdaBoost': {'n_estimators': [10, 20, 40, 80], 'learning_rate': [0.01, 0.1, 1, 10]}\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# function for obtaining best estimator using grid search\n",
    "def grid_search_reg(estimator, params, scoring):\n",
    "    reg = GridSearchCV(estimator, params, scoring = scoring)\n",
    "    reg.fit(X, y)\n",
    "    return (reg.best_estimator_, reg.best_score_)\n",
    "\n",
    "# function for performing k-fold cross validation on the regressors\n",
    "def k_Fold_CV_reg(estimator, n):\n",
    "    mse = []\n",
    "    kf = KFold(n_splits = n)\n",
    "    for train, test in kf.split(X):\n",
    "        pred = estimator.fit(X[train], y[train]).predict(X[test])\n",
    "        mse.append(mean_squared_error(y[test], pred))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_regressors_mse = {}\n",
    "best_regressors_mae = {}\n",
    "for k in regressors:\n",
    "    best_regressors_mse[k], _ = grid_search_reg(regressors[k], params[k], 'neg_mean_squared_error')\n",
    "    best_regressors_mae[k], _ = grid_search_reg(regressors[k], params[k], 'neg_mean_absolute_error')\n",
    "    mse[k] = k_Fold_CV_reg(best_regressors_mse[k], fold)\n",
    "    mae[k] = k_Fold_CV_reg(best_regressors_mae[k], fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for k, v in mse.items():\n",
    "    print(k)\n",
    "    rmse = np.sqrt(v)\n",
    "    print(\"{}_fold RMSE: \".format(fold), np.around(rmse, decimals = 3))\n",
    "    print(\"Average RMSE: {0:0.3f}\".format(np.mean(rmse)))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for k, v in mae.items():\n",
    "    print(k)\n",
    "    print(\"{}_fold MAE: \".format(fold), np.around(v, decimals = 3))\n",
    "    print(\"Average MAE: {0:0.3f}\".format(np.mean(v)))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_regressors_mse = {'AdaBoost': AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='linear',\n",
    "          n_estimators=10, random_state=1),\n",
    " 'MLP': MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "        hidden_layer_sizes=(10,), learning_rate='constant',\n",
    "        learning_rate_init=0.001, max_iter=10000, momentum=0.9,\n",
    "        nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
    "        solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "        warm_start=False),\n",
    " 'Nearest Neighbors': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "           weights='uniform'),\n",
    " 'Random Forest': RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,\n",
    "            max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
    "            oob_score=False, random_state=1, verbose=0, warm_start=False),\n",
    " 'SVM': SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
    "   kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)}\n",
    "\n",
    "best_regressors_mae = {'AdaBoost': AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='linear',\n",
    "          n_estimators=10, random_state=1),\n",
    " 'MLP': MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "        hidden_layer_sizes=(10,), learning_rate='constant',\n",
    "        learning_rate_init=0.001, max_iter=10000, momentum=0.9,\n",
    "        nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
    "        solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "        warm_start=False),\n",
    " 'Nearest Neighbors': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "           weights='uniform'),\n",
    " 'Random Forest': RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,\n",
    "            max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
    "            oob_score=False, random_state=1, verbose=0, warm_start=False),\n",
    " 'SVM': SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
    "   kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_splits = 20\n",
    "X_train, X_test, y_train, y_test = [], [], [], []\n",
    "for i in range(num_splits): \n",
    "    split = train_test_split(X, y, test_size = 0.25)\n",
    "    X_train.append(split[0])\n",
    "    X_test.append(split[1])\n",
    "    y_train.append(split[2])\n",
    "    y_test.append(split[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mserr = {}\n",
    "for k, v in best_regressors_mse.items():\n",
    "    pred = v.fit(X_train, y_train).predict(X_test)\n",
    "    mserr[k] = mean_squared_error(y_test, pred)\n",
    "\n",
    "maerr = {}\n",
    "for k, v in best_regressors_mae.items():\n",
    "    pred = v.fit(X_train, y_train).predict(X_test)\n",
    "    maerr[k] = mean_absolute_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for k, v in mserr.items():\n",
    "    print(k)\n",
    "    print(\"MSE: \", np.around(v, decimals = 3))\n",
    "    print(\"#################################\")\n",
    "    \n",
    "for k, v in maerr.items():\n",
    "    print(k)\n",
    "    print(\"MAE: \", np.around(v, decimals = 3))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_label(score, thresh):\n",
    "    label = []\n",
    "    for s in np.nditer(score):\n",
    "        if s < thresh[0]:\n",
    "            label.append(0)\n",
    "        elif s < thresh[1]:\n",
    "            label.append(1)\n",
    "        else:\n",
    "            label.append(2)\n",
    "    return np.array(label, dtype = int)\n",
    "\n",
    "def optimize_thresh(regressor, X_train, y_train, X_test, y_test, t1_range, top_num):\n",
    "    i = 0\n",
    "    thresh_accuracy = []\n",
    "    model = regressor.fit(X_train, y_train)\n",
    "    pred = model.predict(X_train) \n",
    "    # find optimal thresholds from training set\n",
    "    for t1 in t1_range:\n",
    "        for t2 in np.arange(t1+1, 4.01, 0.05):\n",
    "            y_label_true = to_label(y_train, (t1, t2))\n",
    "            y_label_pred = to_label(pred, (t1, t2))\n",
    "            thresh_accuracy.append(((t1, t2), accuracy_score(y_label_true, y_label_pred)))\n",
    "    thresh_accuracy.sort(key = lambda x:x[1], reverse = True)\n",
    "    # determine average thresholds\n",
    "    thresh = [x[0] for x in thresh_accuracy[:top_num]]\n",
    "    avg_thresh = np.average(thresh, axis = 0) \n",
    "    # find accuracy on test set\n",
    "    pred = model.predict(X_test)\n",
    "    y_label_true = to_label(y_test, avg_thresh)\n",
    "    y_label_pred = to_label(pred, avg_thresh)   \n",
    "    return avg_thresh, accuracy_score(y_label_true, y_label_pred),precision_score(y_label_true, y_label_pred, average = None),recall_score(y_label_true, y_label_pred, average = None), f1_score(y_label_true, y_label_pred, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "t1_range = np.arange(2, 3.01, 0.05)\n",
    "thresh_scores_mse = {}\n",
    "\n",
    "for k, reg in best_regressors_mse.items():\n",
    "    thresh_scores_mse[k] = [optimize_thresh(reg, X_train[i], y_train[i], X_test[i], y_test[i], t1_range, 1) for i in range(num_splits)]\n",
    "\n",
    "thresh_scores_mae = {}\n",
    "for k, reg in best_regressors_mae.items():\n",
    "    thresh_scores_mae[k] = [optimize_thresh(reg, X_train[i], y_train[i], X_test[i], y_test[i], t1_range, 1) for i in range(num_splits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regressors with minimized mean squared error\n",
      "AdaBoost\n",
      "Optimal thresholds: [[2.   4.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.05 4.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.95]\n",
      " [2.   3.  ]\n",
      " [2.   4.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   4.  ]]\n",
      "Accuracy: [0.853 0.92  0.92  0.84  0.84  0.88  0.88  0.947 0.747 0.827 0.893 0.813\n",
      " 0.853 0.88  0.787 0.867 0.867 0.88  0.84  0.8  ]\n",
      "Precision: [[1.    0.741 0.846]\n",
      " [0.92  0.    0.939]\n",
      " [0.962 0.    0.898]\n",
      " [0.955 0.333 0.82 ]\n",
      " [0.826 0.    0.88 ]\n",
      " [0.96  0.    0.857]\n",
      " [0.968 0.333 0.854]\n",
      " [0.958 0.    0.941]\n",
      " [0.889 0.69  0.632]\n",
      " [0.955 0.4   0.812]\n",
      " [1.    0.5   0.86 ]\n",
      " [0.923 0.    0.804]\n",
      " [0.923 0.    0.833]\n",
      " [0.923 0.333 0.891]\n",
      " [0.952 0.643 0.808]\n",
      " [1.    0.    0.804]\n",
      " [0.966 0.8   0.81 ]\n",
      " [1.    0.    0.845]\n",
      " [0.87  0.    0.827]\n",
      " [0.962 0.714 0.714]]\n",
      "Recall: [[0.88  0.87  0.815]\n",
      " [1.    0.    0.958]\n",
      " [1.    0.    1.   ]\n",
      " [0.913 0.111 0.953]\n",
      " [0.95  0.    0.936]\n",
      " [1.    0.    0.977]\n",
      " [1.    0.125 0.946]\n",
      " [0.958 0.    1.   ]\n",
      " [0.828 0.714 0.667]\n",
      " [0.955 0.2   0.907]\n",
      " [0.958 0.125 1.   ]\n",
      " [0.857 0.    0.949]\n",
      " [0.96  0.    0.976]\n",
      " [0.96  0.167 0.932]\n",
      " [0.87  0.75  0.75 ]\n",
      " [0.923 0.    1.   ]\n",
      " [1.    0.8   0.773]\n",
      " [0.85  0.    1.   ]\n",
      " [0.952 0.    0.956]\n",
      " [0.862 0.862 0.588]]\n",
      "F1: [[0.936 0.8   0.83 ]\n",
      " [0.958 0.    0.948]\n",
      " [0.98  0.    0.946]\n",
      " [0.933 0.167 0.882]\n",
      " [0.884 0.    0.907]\n",
      " [0.98  0.    0.913]\n",
      " [0.984 0.182 0.897]\n",
      " [0.958 0.    0.97 ]\n",
      " [0.857 0.702 0.649]\n",
      " [0.955 0.267 0.857]\n",
      " [0.979 0.2   0.925]\n",
      " [0.889 0.    0.871]\n",
      " [0.941 0.    0.899]\n",
      " [0.941 0.222 0.911]\n",
      " [0.909 0.692 0.778]\n",
      " [0.96  0.    0.891]\n",
      " [0.982 0.8   0.791]\n",
      " [0.919 0.    0.916]\n",
      " [0.909 0.    0.887]\n",
      " [0.909 0.781 0.645]]\n",
      "#################################\n",
      "MLP\n",
      "Optimal thresholds: [[2.5  3.8 ]\n",
      " [2.1  3.85]\n",
      " [2.25 3.9 ]\n",
      " [2.05 3.95]\n",
      " [2.1  3.5 ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.15 3.5 ]\n",
      " [2.5  3.75]\n",
      " [2.   3.  ]\n",
      " [2.45 3.8 ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.2  4.  ]\n",
      " [2.15 3.95]\n",
      " [2.   3.  ]\n",
      " [2.15 3.95]\n",
      " [2.25 3.5 ]\n",
      " [2.   3.  ]\n",
      " [2.25 3.8 ]]\n",
      "Accuracy: [0.813 0.853 0.787 0.867 0.813 0.88  0.853 0.747 0.747 0.8   0.827 0.773\n",
      " 0.84  0.8   0.827 0.853 0.787 0.8   0.827 0.787]\n",
      "Precision: [[0.92  0.667 0.828]\n",
      " [0.958 0.708 0.889]\n",
      " [0.955 0.643 0.8  ]\n",
      " [0.905 0.8   0.917]\n",
      " [0.905 0.765 0.784]\n",
      " [1.    0.4   0.87 ]\n",
      " [0.966 0.2   0.854]\n",
      " [0.957 0.632 0.667]\n",
      " [0.897 0.7   0.615]\n",
      " [1.    0.273 0.841]\n",
      " [0.958 0.714 0.8  ]\n",
      " [1.    0.1   0.814]\n",
      " [0.958 0.25  0.83 ]\n",
      " [0.885 0.667 0.84 ]\n",
      " [0.952 0.69  0.88 ]\n",
      " [0.96  0.    0.816]\n",
      " [0.963 0.643 0.75 ]\n",
      " [1.    0.833 0.711]\n",
      " [1.    0.385 0.884]\n",
      " [0.963 0.724 0.632]]\n",
      "Recall: [[0.92  0.7   0.8  ]\n",
      " [1.    0.81  0.774]\n",
      " [0.84  0.75  0.769]\n",
      " [0.826 0.857 0.917]\n",
      " [0.95  0.565 0.906]\n",
      " [1.    0.25  0.93 ]\n",
      " [0.933 0.125 0.946]\n",
      " [0.917 0.522 0.786]\n",
      " [0.897 0.538 0.8  ]\n",
      " [0.909 0.3   0.86 ]\n",
      " [0.958 0.682 0.828]\n",
      " [0.786 0.125 0.897]\n",
      " [0.92  0.111 0.951]\n",
      " [0.92  0.696 0.778]\n",
      " [0.87  0.833 0.786]\n",
      " [0.923 0.    0.976]\n",
      " [0.929 0.75  0.652]\n",
      " [0.9   0.435 1.   ]\n",
      " [0.905 0.556 0.844]\n",
      " [0.897 0.75  0.667]]\n",
      "F1: [[0.92  0.683 0.814]\n",
      " [0.979 0.756 0.828]\n",
      " [0.894 0.692 0.784]\n",
      " [0.864 0.828 0.917]\n",
      " [0.927 0.65  0.841]\n",
      " [1.    0.308 0.899]\n",
      " [0.949 0.154 0.897]\n",
      " [0.936 0.571 0.721]\n",
      " [0.897 0.609 0.696]\n",
      " [0.952 0.286 0.851]\n",
      " [0.958 0.698 0.814]\n",
      " [0.88  0.111 0.854]\n",
      " [0.939 0.154 0.886]\n",
      " [0.902 0.681 0.808]\n",
      " [0.909 0.755 0.83 ]\n",
      " [0.941 0.    0.889]\n",
      " [0.945 0.692 0.698]\n",
      " [0.947 0.571 0.831]\n",
      " [0.95  0.455 0.864]\n",
      " [0.929 0.737 0.649]]\n",
      "#################################\n",
      "Nearest Neighbors\n",
      "Optimal thresholds: [[2.   3.  ]\n",
      " [2.6  3.8 ]\n",
      " [2.6  3.85]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.4  3.65]\n",
      " [2.6  3.9 ]\n",
      " [2.6  3.95]\n",
      " [2.25 3.85]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.55 3.95]\n",
      " [2.   3.  ]\n",
      " [2.6  3.7 ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]]\n",
      "Accuracy: [0.773 0.773 0.667 0.867 0.813 0.707 0.867 0.773 0.64  0.76  0.787 0.68\n",
      " 0.813 0.72  0.773 0.827 0.827 0.827 0.8   0.747]\n",
      "Precision: [[1.    0.182 0.83 ]\n",
      " [0.917 0.591 0.793]\n",
      " [0.957 0.483 0.609]\n",
      " [1.    0.5   0.86 ]\n",
      " [1.    0.143 0.849]\n",
      " [1.    0.619 0.588]\n",
      " [0.967 0.857 0.75 ]\n",
      " [0.909 0.731 0.704]\n",
      " [0.958 0.5   0.48 ]\n",
      " [1.    0.    0.784]\n",
      " [0.95  0.182 0.864]\n",
      " [1.    0.5   0.56 ]\n",
      " [0.952 0.286 0.83 ]\n",
      " [0.875 0.615 0.658]\n",
      " [0.938 0.    0.827]\n",
      " [1.    0.    0.804]\n",
      " [0.917 0.143 0.886]\n",
      " [1.    0.    0.891]\n",
      " [1.    0.167 0.811]\n",
      " [0.95  0.091 0.818]]\n",
      "Recall: [[0.68  0.286 0.907]\n",
      " [0.957 0.619 0.742]\n",
      " [0.88  0.583 0.538]\n",
      " [0.826 0.333 1.   ]\n",
      " [0.75  0.125 0.957]\n",
      " [0.833 0.52  0.769]\n",
      " [0.967 0.72  0.9  ]\n",
      " [0.833 0.679 0.826]\n",
      " [0.793 0.5   0.6  ]\n",
      " [0.773 0.    0.93 ]\n",
      " [0.792 0.25  0.884]\n",
      " [0.857 0.542 0.609]\n",
      " [0.8   0.222 0.951]\n",
      " [0.84  0.348 0.926]\n",
      " [0.652 0.    0.956]\n",
      " [0.808 0.    1.   ]\n",
      " [0.786 0.167 0.951]\n",
      " [0.65  0.    1.   ]\n",
      " [0.762 0.111 0.956]\n",
      " [0.655 0.125 0.947]]\n",
      "F1: [[0.81  0.222 0.867]\n",
      " [0.936 0.605 0.767]\n",
      " [0.917 0.528 0.571]\n",
      " [0.905 0.4   0.925]\n",
      " [0.857 0.133 0.9  ]\n",
      " [0.909 0.565 0.667]\n",
      " [0.967 0.783 0.818]\n",
      " [0.87  0.704 0.76 ]\n",
      " [0.868 0.5   0.533]\n",
      " [0.872 0.    0.851]\n",
      " [0.864 0.211 0.874]\n",
      " [0.923 0.52  0.583]\n",
      " [0.87  0.25  0.886]\n",
      " [0.857 0.444 0.769]\n",
      " [0.769 0.    0.887]\n",
      " [0.894 0.    0.891]\n",
      " [0.846 0.154 0.918]\n",
      " [0.788 0.    0.942]\n",
      " [0.865 0.133 0.878]\n",
      " [0.776 0.105 0.878]]\n",
      "#################################\n",
      "Random Forest\n",
      "Optimal thresholds: [[2.   3.8 ]\n",
      " [2.25 3.95]\n",
      " [2.35 3.8 ]\n",
      " [2.   3.85]\n",
      " [2.4  3.95]\n",
      " [2.4  3.85]\n",
      " [2.3  3.75]\n",
      " [2.   3.85]\n",
      " [2.35 3.7 ]\n",
      " [2.55 3.95]\n",
      " [2.   4.  ]\n",
      " [2.   3.85]\n",
      " [2.   4.  ]\n",
      " [2.05 4.  ]\n",
      " [2.5  3.95]\n",
      " [2.3  3.9 ]\n",
      " [2.35 3.8 ]\n",
      " [2.3  3.4 ]\n",
      " [2.   4.  ]\n",
      " [2.55 4.  ]]\n",
      "Accuracy: [0.787 0.84  0.893 0.813 0.827 0.853 0.893 0.827 0.72  0.893 0.84  0.773\n",
      " 0.813 0.813 0.827 0.853 0.853 0.84  0.84  0.813]\n",
      "Precision: [[1.    0.593 0.828]\n",
      " [0.958 0.696 0.857]\n",
      " [0.962 0.9   0.828]\n",
      " [0.9   0.733 0.84 ]\n",
      " [0.792 0.783 0.893]\n",
      " [0.96  0.85  0.767]\n",
      " [0.968 0.947 0.76 ]\n",
      " [0.957 0.8   0.741]\n",
      " [0.897 0.636 0.583]\n",
      " [0.957 0.897 0.826]\n",
      " [1.    0.704 0.852]\n",
      " [0.923 0.684 0.7  ]\n",
      " [0.909 0.741 0.808]\n",
      " [0.96  0.737 0.742]\n",
      " [0.955 0.69  0.875]\n",
      " [1.    0.69  0.909]\n",
      " [0.933 0.85  0.76 ]\n",
      " [1.    0.909 0.756]\n",
      " [0.947 0.793 0.815]\n",
      " [0.962 0.703 0.833]]\n",
      "Recall: [[0.76  0.8   0.8  ]\n",
      " [1.    0.762 0.774]\n",
      " [1.    0.75  0.923]\n",
      " [0.783 0.815 0.84 ]\n",
      " [0.95  0.692 0.862]\n",
      " [1.    0.68  0.885]\n",
      " [1.    0.72  0.95 ]\n",
      " [0.917 0.741 0.833]\n",
      " [0.897 0.56  0.667]\n",
      " [1.    0.867 0.826]\n",
      " [0.875 0.826 0.821]\n",
      " [0.857 0.565 0.875]\n",
      " [0.8   0.769 0.875]\n",
      " [0.96  0.609 0.852]\n",
      " [0.913 0.833 0.75 ]\n",
      " [0.923 0.952 0.714]\n",
      " [1.    0.708 0.826]\n",
      " [0.95  0.476 1.   ]\n",
      " [0.857 0.821 0.846]\n",
      " [0.862 0.897 0.588]]\n",
      "F1: [[0.864 0.681 0.814]\n",
      " [0.979 0.727 0.814]\n",
      " [0.98  0.818 0.873]\n",
      " [0.837 0.772 0.84 ]\n",
      " [0.864 0.735 0.877]\n",
      " [0.98  0.756 0.821]\n",
      " [0.984 0.818 0.844]\n",
      " [0.936 0.769 0.784]\n",
      " [0.897 0.596 0.622]\n",
      " [0.978 0.881 0.826]\n",
      " [0.933 0.76  0.836]\n",
      " [0.889 0.619 0.778]\n",
      " [0.851 0.755 0.84 ]\n",
      " [0.96  0.667 0.793]\n",
      " [0.933 0.755 0.808]\n",
      " [0.96  0.8   0.8  ]\n",
      " [0.966 0.773 0.792]\n",
      " [0.974 0.625 0.861]\n",
      " [0.9   0.807 0.83 ]\n",
      " [0.909 0.788 0.69 ]]\n",
      "#################################\n",
      "SVM\n",
      "Optimal thresholds: [[2.   3.  ]\n",
      " [2.25 3.8 ]\n",
      " [2.25 4.  ]\n",
      " [2.   3.  ]\n",
      " [2.55 3.55]\n",
      " [2.3  3.95]\n",
      " [2.   3.  ]\n",
      " [2.4  3.5 ]\n",
      " [2.4  3.85]\n",
      " [2.05 3.05]\n",
      " [2.   3.  ]\n",
      " [2.05 3.9 ]\n",
      " [2.   3.  ]\n",
      " [2.45 3.95]\n",
      " [2.45 4.  ]\n",
      " [2.   3.  ]\n",
      " [2.25 4.  ]\n",
      " [2.45 4.  ]\n",
      " [2.   3.  ]\n",
      " [2.4  4.  ]]\n",
      "Accuracy: [0.84  0.88  0.827 0.84  0.773 0.853 0.893 0.773 0.747 0.773 0.787 0.773\n",
      " 0.813 0.773 0.867 0.8   0.853 0.827 0.787 0.8  ]\n",
      "Precision: [[1.    0.3   0.891]\n",
      " [0.958 0.731 0.96 ]\n",
      " [0.958 0.76  0.769]\n",
      " [0.944 0.385 0.932]\n",
      " [0.833 0.688 0.771]\n",
      " [0.96  0.864 0.75 ]\n",
      " [1.    0.5   0.875]\n",
      " [0.958 0.769 0.658]\n",
      " [0.929 0.654 0.619]\n",
      " [1.    0.364 0.773]\n",
      " [1.    0.167 0.864]\n",
      " [1.    0.625 0.714]\n",
      " [0.957 0.167 0.826]\n",
      " [0.889 0.652 0.76 ]\n",
      " [0.92  0.87  0.815]\n",
      " [1.    0.125 0.822]\n",
      " [0.966 0.792 0.773]\n",
      " [1.    0.731 0.806]\n",
      " [1.    0.286 0.864]\n",
      " [0.963 0.742 0.647]]\n",
      "Recall: [[0.76  0.429 0.953]\n",
      " [1.    0.905 0.774]\n",
      " [0.92  0.731 0.833]\n",
      " [0.739 0.556 0.953]\n",
      " [1.    0.478 0.844]\n",
      " [1.    0.704 0.875]\n",
      " [0.967 0.375 0.946]\n",
      " [0.958 0.435 0.893]\n",
      " [0.897 0.654 0.65 ]\n",
      " [0.909 0.286 0.872]\n",
      " [0.792 0.25  0.884]\n",
      " [0.821 0.652 0.833]\n",
      " [0.88  0.111 0.927]\n",
      " [0.96  0.652 0.704]\n",
      " [1.    0.769 0.846]\n",
      " [0.846 0.125 0.902]\n",
      " [1.    0.76  0.773]\n",
      " [0.9   0.76  0.833]\n",
      " [0.81  0.444 0.844]\n",
      " [0.897 0.793 0.647]]\n",
      "F1: [[0.864 0.353 0.921]\n",
      " [0.979 0.809 0.857]\n",
      " [0.939 0.745 0.8  ]\n",
      " [0.829 0.455 0.943]\n",
      " [0.909 0.564 0.806]\n",
      " [0.98  0.776 0.808]\n",
      " [0.983 0.429 0.909]\n",
      " [0.958 0.556 0.758]\n",
      " [0.912 0.654 0.634]\n",
      " [0.952 0.32  0.819]\n",
      " [0.884 0.2   0.874]\n",
      " [0.902 0.638 0.769]\n",
      " [0.917 0.133 0.874]\n",
      " [0.923 0.652 0.731]\n",
      " [0.958 0.816 0.83 ]\n",
      " [0.917 0.125 0.86 ]\n",
      " [0.982 0.776 0.773]\n",
      " [0.947 0.745 0.82 ]\n",
      " [0.895 0.348 0.854]\n",
      " [0.929 0.767 0.647]]\n",
      "#################################\n",
      "\n",
      "regressors with minimized mean absolute error\n",
      "AdaBoost\n",
      "Optimal thresholds: [[2.   3.  ]\n",
      " [2.   4.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   4.  ]\n",
      " [2.   4.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.65 4.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.95]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]]\n",
      "Accuracy: [0.867 0.893 0.92  0.84  0.853 0.893 0.907 0.88  0.76  0.827 0.853 0.827\n",
      " 0.88  0.867 0.773 0.853 0.893 0.893 0.827 0.867]\n",
      "Precision: [[0.958 0.    0.84 ]\n",
      " [0.958 0.818 0.897]\n",
      " [0.962 0.    0.898]\n",
      " [0.913 0.    0.824]\n",
      " [0.833 0.    0.88 ]\n",
      " [0.96  0.    0.86 ]\n",
      " [0.968 1.    0.86 ]\n",
      " [0.958 0.885 0.8  ]\n",
      " [0.923 0.7   0.632]\n",
      " [0.905 0.5   0.82 ]\n",
      " [1.    0.    0.808]\n",
      " [0.926 0.    0.804]\n",
      " [0.923 0.84  0.875]\n",
      " [0.92  0.25  0.891]\n",
      " [0.909 0.63  0.808]\n",
      " [1.    0.    0.816]\n",
      " [0.966 0.    0.886]\n",
      " [1.    0.5   0.873]\n",
      " [0.833 0.    0.824]\n",
      " [0.964 0.    0.809]]\n",
      "Recall: [[0.92  0.    0.977]\n",
      " [1.    0.818 0.867]\n",
      " [1.    0.    1.   ]\n",
      " [0.913 0.    0.977]\n",
      " [1.    0.    0.936]\n",
      " [1.    0.    1.   ]\n",
      " [1.    0.125 1.   ]\n",
      " [0.958 0.821 0.87 ]\n",
      " [0.828 0.75  0.667]\n",
      " [0.864 0.2   0.953]\n",
      " [0.917 0.    0.977]\n",
      " [0.893 0.    0.949]\n",
      " [0.923 0.84  0.875]\n",
      " [0.92  0.167 0.932]\n",
      " [0.87  0.708 0.75 ]\n",
      " [0.923 0.    0.976]\n",
      " [1.    0.    0.951]\n",
      " [0.9   0.167 0.98 ]\n",
      " [0.952 0.    0.933]\n",
      " [0.931 0.    1.   ]]\n",
      "F1: [[0.939 0.    0.903]\n",
      " [0.979 0.818 0.881]\n",
      " [0.98  0.    0.946]\n",
      " [0.913 0.    0.894]\n",
      " [0.909 0.    0.907]\n",
      " [0.98  0.    0.925]\n",
      " [0.984 0.222 0.925]\n",
      " [0.958 0.852 0.833]\n",
      " [0.873 0.724 0.649]\n",
      " [0.884 0.286 0.882]\n",
      " [0.957 0.    0.884]\n",
      " [0.909 0.    0.871]\n",
      " [0.923 0.84  0.875]\n",
      " [0.92  0.2   0.911]\n",
      " [0.889 0.667 0.778]\n",
      " [0.96  0.    0.889]\n",
      " [0.982 0.    0.918]\n",
      " [0.947 0.25  0.923]\n",
      " [0.889 0.    0.875]\n",
      " [0.947 0.    0.894]]\n",
      "#################################\n",
      "MLP\n",
      "Optimal thresholds: [[2.5  3.8 ]\n",
      " [2.1  3.85]\n",
      " [2.25 3.9 ]\n",
      " [2.05 3.95]\n",
      " [2.1  3.5 ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.15 3.5 ]\n",
      " [2.5  3.75]\n",
      " [2.   3.  ]\n",
      " [2.45 3.8 ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.2  4.  ]\n",
      " [2.15 3.95]\n",
      " [2.   3.  ]\n",
      " [2.15 3.95]\n",
      " [2.25 3.5 ]\n",
      " [2.   3.  ]\n",
      " [2.25 3.8 ]]\n",
      "Accuracy: [0.813 0.853 0.787 0.867 0.813 0.88  0.853 0.747 0.747 0.8   0.827 0.773\n",
      " 0.84  0.8   0.827 0.853 0.787 0.8   0.827 0.787]\n",
      "Precision: [[0.92  0.667 0.828]\n",
      " [0.958 0.708 0.889]\n",
      " [0.955 0.643 0.8  ]\n",
      " [0.905 0.8   0.917]\n",
      " [0.905 0.765 0.784]\n",
      " [1.    0.4   0.87 ]\n",
      " [0.966 0.2   0.854]\n",
      " [0.957 0.632 0.667]\n",
      " [0.897 0.7   0.615]\n",
      " [1.    0.273 0.841]\n",
      " [0.958 0.714 0.8  ]\n",
      " [1.    0.1   0.814]\n",
      " [0.958 0.25  0.83 ]\n",
      " [0.885 0.667 0.84 ]\n",
      " [0.952 0.69  0.88 ]\n",
      " [0.96  0.    0.816]\n",
      " [0.963 0.643 0.75 ]\n",
      " [1.    0.833 0.711]\n",
      " [1.    0.385 0.884]\n",
      " [0.963 0.724 0.632]]\n",
      "Recall: [[0.92  0.7   0.8  ]\n",
      " [1.    0.81  0.774]\n",
      " [0.84  0.75  0.769]\n",
      " [0.826 0.857 0.917]\n",
      " [0.95  0.565 0.906]\n",
      " [1.    0.25  0.93 ]\n",
      " [0.933 0.125 0.946]\n",
      " [0.917 0.522 0.786]\n",
      " [0.897 0.538 0.8  ]\n",
      " [0.909 0.3   0.86 ]\n",
      " [0.958 0.682 0.828]\n",
      " [0.786 0.125 0.897]\n",
      " [0.92  0.111 0.951]\n",
      " [0.92  0.696 0.778]\n",
      " [0.87  0.833 0.786]\n",
      " [0.923 0.    0.976]\n",
      " [0.929 0.75  0.652]\n",
      " [0.9   0.435 1.   ]\n",
      " [0.905 0.556 0.844]\n",
      " [0.897 0.75  0.667]]\n",
      "F1: [[0.92  0.683 0.814]\n",
      " [0.979 0.756 0.828]\n",
      " [0.894 0.692 0.784]\n",
      " [0.864 0.828 0.917]\n",
      " [0.927 0.65  0.841]\n",
      " [1.    0.308 0.899]\n",
      " [0.949 0.154 0.897]\n",
      " [0.936 0.571 0.721]\n",
      " [0.897 0.609 0.696]\n",
      " [0.952 0.286 0.851]\n",
      " [0.958 0.698 0.814]\n",
      " [0.88  0.111 0.854]\n",
      " [0.939 0.154 0.886]\n",
      " [0.902 0.681 0.808]\n",
      " [0.909 0.755 0.83 ]\n",
      " [0.941 0.    0.889]\n",
      " [0.945 0.692 0.698]\n",
      " [0.947 0.571 0.831]\n",
      " [0.95  0.455 0.864]\n",
      " [0.929 0.737 0.649]]\n",
      "#################################\n",
      "Nearest Neighbors\n",
      "Optimal thresholds: [[2.   3.  ]\n",
      " [2.6  3.8 ]\n",
      " [2.6  3.85]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.4  3.65]\n",
      " [2.6  3.9 ]\n",
      " [2.6  3.95]\n",
      " [2.25 3.85]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.55 3.95]\n",
      " [2.   3.  ]\n",
      " [2.6  3.7 ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]\n",
      " [2.   3.  ]]\n",
      "Accuracy: [0.773 0.773 0.667 0.867 0.813 0.707 0.867 0.773 0.64  0.76  0.787 0.68\n",
      " 0.813 0.72  0.773 0.827 0.827 0.827 0.8   0.747]\n",
      "Precision: [[1.    0.182 0.83 ]\n",
      " [0.917 0.591 0.793]\n",
      " [0.957 0.483 0.609]\n",
      " [1.    0.5   0.86 ]\n",
      " [1.    0.143 0.849]\n",
      " [1.    0.619 0.588]\n",
      " [0.967 0.857 0.75 ]\n",
      " [0.909 0.731 0.704]\n",
      " [0.958 0.5   0.48 ]\n",
      " [1.    0.    0.784]\n",
      " [0.95  0.182 0.864]\n",
      " [1.    0.5   0.56 ]\n",
      " [0.952 0.286 0.83 ]\n",
      " [0.875 0.615 0.658]\n",
      " [0.938 0.    0.827]\n",
      " [1.    0.    0.804]\n",
      " [0.917 0.143 0.886]\n",
      " [1.    0.    0.891]\n",
      " [1.    0.167 0.811]\n",
      " [0.95  0.091 0.818]]\n",
      "Recall: [[0.68  0.286 0.907]\n",
      " [0.957 0.619 0.742]\n",
      " [0.88  0.583 0.538]\n",
      " [0.826 0.333 1.   ]\n",
      " [0.75  0.125 0.957]\n",
      " [0.833 0.52  0.769]\n",
      " [0.967 0.72  0.9  ]\n",
      " [0.833 0.679 0.826]\n",
      " [0.793 0.5   0.6  ]\n",
      " [0.773 0.    0.93 ]\n",
      " [0.792 0.25  0.884]\n",
      " [0.857 0.542 0.609]\n",
      " [0.8   0.222 0.951]\n",
      " [0.84  0.348 0.926]\n",
      " [0.652 0.    0.956]\n",
      " [0.808 0.    1.   ]\n",
      " [0.786 0.167 0.951]\n",
      " [0.65  0.    1.   ]\n",
      " [0.762 0.111 0.956]\n",
      " [0.655 0.125 0.947]]\n",
      "F1: [[0.81  0.222 0.867]\n",
      " [0.936 0.605 0.767]\n",
      " [0.917 0.528 0.571]\n",
      " [0.905 0.4   0.925]\n",
      " [0.857 0.133 0.9  ]\n",
      " [0.909 0.565 0.667]\n",
      " [0.967 0.783 0.818]\n",
      " [0.87  0.704 0.76 ]\n",
      " [0.868 0.5   0.533]\n",
      " [0.872 0.    0.851]\n",
      " [0.864 0.211 0.874]\n",
      " [0.923 0.52  0.583]\n",
      " [0.87  0.25  0.886]\n",
      " [0.857 0.444 0.769]\n",
      " [0.769 0.    0.887]\n",
      " [0.894 0.    0.891]\n",
      " [0.846 0.154 0.918]\n",
      " [0.788 0.    0.942]\n",
      " [0.865 0.133 0.878]\n",
      " [0.776 0.105 0.878]]\n",
      "#################################\n",
      "Random Forest\n",
      "Optimal thresholds: [[2.   3.8 ]\n",
      " [2.25 3.95]\n",
      " [2.35 3.8 ]\n",
      " [2.   3.85]\n",
      " [2.4  3.95]\n",
      " [2.4  3.85]\n",
      " [2.3  3.75]\n",
      " [2.   3.85]\n",
      " [2.35 3.7 ]\n",
      " [2.55 3.95]\n",
      " [2.   4.  ]\n",
      " [2.   3.85]\n",
      " [2.   4.  ]\n",
      " [2.05 4.  ]\n",
      " [2.5  3.95]\n",
      " [2.3  3.9 ]\n",
      " [2.35 3.8 ]\n",
      " [2.3  3.4 ]\n",
      " [2.   4.  ]\n",
      " [2.55 4.  ]]\n",
      "Accuracy: [0.787 0.84  0.893 0.813 0.827 0.853 0.893 0.827 0.72  0.893 0.84  0.773\n",
      " 0.813 0.813 0.827 0.853 0.853 0.84  0.84  0.813]\n",
      "Precision: [[1.    0.593 0.828]\n",
      " [0.958 0.696 0.857]\n",
      " [0.962 0.9   0.828]\n",
      " [0.9   0.733 0.84 ]\n",
      " [0.792 0.783 0.893]\n",
      " [0.96  0.85  0.767]\n",
      " [0.968 0.947 0.76 ]\n",
      " [0.957 0.8   0.741]\n",
      " [0.897 0.636 0.583]\n",
      " [0.957 0.897 0.826]\n",
      " [1.    0.704 0.852]\n",
      " [0.923 0.684 0.7  ]\n",
      " [0.909 0.741 0.808]\n",
      " [0.96  0.737 0.742]\n",
      " [0.955 0.69  0.875]\n",
      " [1.    0.69  0.909]\n",
      " [0.933 0.85  0.76 ]\n",
      " [1.    0.909 0.756]\n",
      " [0.947 0.793 0.815]\n",
      " [0.962 0.703 0.833]]\n",
      "Recall: [[0.76  0.8   0.8  ]\n",
      " [1.    0.762 0.774]\n",
      " [1.    0.75  0.923]\n",
      " [0.783 0.815 0.84 ]\n",
      " [0.95  0.692 0.862]\n",
      " [1.    0.68  0.885]\n",
      " [1.    0.72  0.95 ]\n",
      " [0.917 0.741 0.833]\n",
      " [0.897 0.56  0.667]\n",
      " [1.    0.867 0.826]\n",
      " [0.875 0.826 0.821]\n",
      " [0.857 0.565 0.875]\n",
      " [0.8   0.769 0.875]\n",
      " [0.96  0.609 0.852]\n",
      " [0.913 0.833 0.75 ]\n",
      " [0.923 0.952 0.714]\n",
      " [1.    0.708 0.826]\n",
      " [0.95  0.476 1.   ]\n",
      " [0.857 0.821 0.846]\n",
      " [0.862 0.897 0.588]]\n",
      "F1: [[0.864 0.681 0.814]\n",
      " [0.979 0.727 0.814]\n",
      " [0.98  0.818 0.873]\n",
      " [0.837 0.772 0.84 ]\n",
      " [0.864 0.735 0.877]\n",
      " [0.98  0.756 0.821]\n",
      " [0.984 0.818 0.844]\n",
      " [0.936 0.769 0.784]\n",
      " [0.897 0.596 0.622]\n",
      " [0.978 0.881 0.826]\n",
      " [0.933 0.76  0.836]\n",
      " [0.889 0.619 0.778]\n",
      " [0.851 0.755 0.84 ]\n",
      " [0.96  0.667 0.793]\n",
      " [0.933 0.755 0.808]\n",
      " [0.96  0.8   0.8  ]\n",
      " [0.966 0.773 0.792]\n",
      " [0.974 0.625 0.861]\n",
      " [0.9   0.807 0.83 ]\n",
      " [0.909 0.788 0.69 ]]\n",
      "#################################\n",
      "SVM\n",
      "Optimal thresholds: [[2.   3.  ]\n",
      " [2.25 3.8 ]\n",
      " [2.25 4.  ]\n",
      " [2.   3.  ]\n",
      " [2.55 3.55]\n",
      " [2.3  3.95]\n",
      " [2.   3.  ]\n",
      " [2.4  3.5 ]\n",
      " [2.4  3.85]\n",
      " [2.05 3.05]\n",
      " [2.   3.  ]\n",
      " [2.05 3.9 ]\n",
      " [2.   3.  ]\n",
      " [2.45 3.95]\n",
      " [2.45 4.  ]\n",
      " [2.   3.  ]\n",
      " [2.25 4.  ]\n",
      " [2.45 4.  ]\n",
      " [2.   3.  ]\n",
      " [2.4  4.  ]]\n",
      "Accuracy: [0.84  0.88  0.827 0.84  0.773 0.853 0.893 0.773 0.747 0.773 0.787 0.773\n",
      " 0.813 0.773 0.867 0.8   0.853 0.827 0.787 0.8  ]\n",
      "Precision: [[1.    0.3   0.891]\n",
      " [0.958 0.731 0.96 ]\n",
      " [0.958 0.76  0.769]\n",
      " [0.944 0.385 0.932]\n",
      " [0.833 0.688 0.771]\n",
      " [0.96  0.864 0.75 ]\n",
      " [1.    0.5   0.875]\n",
      " [0.958 0.769 0.658]\n",
      " [0.929 0.654 0.619]\n",
      " [1.    0.364 0.773]\n",
      " [1.    0.167 0.864]\n",
      " [1.    0.625 0.714]\n",
      " [0.957 0.167 0.826]\n",
      " [0.889 0.652 0.76 ]\n",
      " [0.92  0.87  0.815]\n",
      " [1.    0.125 0.822]\n",
      " [0.966 0.792 0.773]\n",
      " [1.    0.731 0.806]\n",
      " [1.    0.286 0.864]\n",
      " [0.963 0.742 0.647]]\n",
      "Recall: [[0.76  0.429 0.953]\n",
      " [1.    0.905 0.774]\n",
      " [0.92  0.731 0.833]\n",
      " [0.739 0.556 0.953]\n",
      " [1.    0.478 0.844]\n",
      " [1.    0.704 0.875]\n",
      " [0.967 0.375 0.946]\n",
      " [0.958 0.435 0.893]\n",
      " [0.897 0.654 0.65 ]\n",
      " [0.909 0.286 0.872]\n",
      " [0.792 0.25  0.884]\n",
      " [0.821 0.652 0.833]\n",
      " [0.88  0.111 0.927]\n",
      " [0.96  0.652 0.704]\n",
      " [1.    0.769 0.846]\n",
      " [0.846 0.125 0.902]\n",
      " [1.    0.76  0.773]\n",
      " [0.9   0.76  0.833]\n",
      " [0.81  0.444 0.844]\n",
      " [0.897 0.793 0.647]]\n",
      "F1: [[0.864 0.353 0.921]\n",
      " [0.979 0.809 0.857]\n",
      " [0.939 0.745 0.8  ]\n",
      " [0.829 0.455 0.943]\n",
      " [0.909 0.564 0.806]\n",
      " [0.98  0.776 0.808]\n",
      " [0.983 0.429 0.909]\n",
      " [0.958 0.556 0.758]\n",
      " [0.912 0.654 0.634]\n",
      " [0.952 0.32  0.819]\n",
      " [0.884 0.2   0.874]\n",
      " [0.902 0.638 0.769]\n",
      " [0.917 0.133 0.874]\n",
      " [0.923 0.652 0.731]\n",
      " [0.958 0.816 0.83 ]\n",
      " [0.917 0.125 0.86 ]\n",
      " [0.982 0.776 0.773]\n",
      " [0.947 0.745 0.82 ]\n",
      " [0.895 0.348 0.854]\n",
      " [0.929 0.767 0.647]]\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "print('regressors with minimized mean squared error')\n",
    "for k, v in thresh_scores_mse.items():\n",
    "    print(k)\n",
    "    print(\"Optimal thresholds: {}\".format(np.around([x[0] for x in v], decimals = 2)))\n",
    "    print(\"Accuracy: {}\".format(np.around([x[1] for x in v], decimals = 3)))\n",
    "    print(\"Precision: {}\".format(np.around([x[2] for x in v], decimals = 3)))\n",
    "    print(\"Recall: {}\".format(np.around([x[3] for x in v], decimals = 3)))\n",
    "    print(\"F1: {}\".format(np.around([x[4] for x in v], decimals = 3)))\n",
    "    print(\"#################################\")    \n",
    "    \n",
    "print()\n",
    "print('regressors with minimized mean absolute error')\n",
    "for k, v in thresh_scores_mae.items():\n",
    "    print(k)\n",
    "    print(\"Optimal thresholds: {}\".format(np.around([x[0] for x in v], decimals = 2)))\n",
    "    print(\"Accuracy: {}\".format(np.around([x[1] for x in v], decimals = 3)))\n",
    "    print(\"Precision: {}\".format(np.around([x[2] for x in v], decimals = 3)))\n",
    "    print(\"Recall: {}\".format(np.around([x[3] for x in v], decimals = 3)))\n",
    "    print(\"F1: {}\".format(np.around([x[4] for x in v], decimals = 3)))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Averaging\n",
    "avg_thresh_scores_mse = {}\n",
    "avg_thresh_scores_mae = {}\n",
    "metrics = ['thresholds', 'accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "for k, v in thresh_scores_mse.items():\n",
    "    avg_thresh_scores_mse[k] = {}\n",
    "    for i, m in enumerate(metrics):\n",
    "        avg_thresh_scores_mse[k][m] = np.average([x[i] for x in v], axis = 0)\n",
    "        \n",
    "for k, v in thresh_scores_mae.items():\n",
    "    avg_thresh_scores_mae[k] = {}\n",
    "    for i, m in enumerate(metrics):\n",
    "        avg_thresh_scores_mae[k][m] = np.average([x[i] for x in v], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AdaBoost': {'accuracy': 0.8566666666666668,\n",
       "  'f1': array([0.93818915, 0.24063429, 0.86562587]),\n",
       "  'precision': array([0.94549566, 0.27437694, 0.83375525]),\n",
       "  'recall': array([0.93380384, 0.23618488, 0.90409021]),\n",
       "  'thresholds': array([2.0025, 3.2475])},\n",
       " 'MLP': {'accuracy': 0.8140000000000001,\n",
       "  'f1': array([0.93088964, 0.51945384, 0.8184018 ]),\n",
       "  'precision': array([0.95502911, 0.53962103, 0.8009794 ]),\n",
       "  'recall': array([0.90991522, 0.51771688, 0.84336637]),\n",
       "  'thresholds': array([2.155 , 3.5125])},\n",
       " 'Nearest Neighbors': {'accuracy': 0.772,\n",
       "  'f1': array([0.86799922, 0.31287259, 0.80823433]),\n",
       "  'precision': array([0.96444135, 0.32943264, 0.7597917 ]),\n",
       "  'recall': array([0.794662  , 0.30647464, 0.8674816 ]),\n",
       "  'thresholds': array([2.21  , 3.3325])},\n",
       " 'Random Forest': {'accuracy': 0.8306666666666667,\n",
       "  'f1': array([0.92864411, 0.7450385 , 0.8071371 ]),\n",
       "  'precision': array([0.94689146, 0.76670875, 0.79856372]),\n",
       "  'recall': array([0.91516511, 0.74219419, 0.8254042 ]),\n",
       "  'thresholds': array([2.2325, 3.8675])},\n",
       " 'SVM': {'accuracy': 0.8140000000000001,\n",
       "  'f1': array([0.92793451, 0.54294569, 0.81429718]),\n",
       "  'precision': array([0.961762  , 0.55841962, 0.79446858]),\n",
       "  'recall': array([0.90275488, 0.54341017, 0.83937978]),\n",
       "  'thresholds': array([2.2125, 3.5275])}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_thresh_scores_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S2, S6 and Pixel Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = {}\n",
    "df['s2'] = pd.read_table(dr + 's2.txt', delim_whitespace=True, dtype = dtype)\n",
    "df['s6'] = pd.read_table(dr + 's6.txt', delim_whitespace=True, dtype = dtype)\n",
    "df['px'] = pd.read_table(dr + 'pixel.txt', delim_whitespace=True, dtype = dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for d in df.values():\n",
    "    d['BitRate'] /= 100     # transforming BitRate to percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = {}\n",
    "y = {}\n",
    "# y_bin = {}\n",
    "for k, d in df.items():\n",
    "    X[k], y[k] = np.array(d[features]), np.array(d['Quality'])\n",
    "    # y_bin[k] = label_binarize(y[k], classes = classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#mae = {}\n",
    "\n",
    "thresh = {}\n",
    "accuracy = {}\n",
    "'''\n",
    "acc = {}\n",
    "prec = {}\n",
    "recl = {}\n",
    "f1 = {}\n",
    "'''\n",
    "for r, reg in best_regressors_mae.items():\n",
    "    #mae[r] = {}\n",
    "    thresh[r] = {}\n",
    "    '''\n",
    "    acc[r] = {}\n",
    "    prec[r] = {}\n",
    "    recl[r] = {} \n",
    "    f1[r] = {}    \n",
    "    '''\n",
    "    for k in X.keys():\n",
    "        #mae[r][k] = {}\n",
    "        thresh[r][k] = {}\n",
    "        '''\n",
    "        acc[r][k] = {}\n",
    "        prec[r][k] = {}\n",
    "        recl[r][k] = {} \n",
    "        f1[r][k] = {}\n",
    "        '''\n",
    "        for k1 in X.keys():\n",
    "            if k1 != k: # train and test on other datasets\n",
    "                #pred = reg.fit(X[k], y[k]).predict(X[k1])\n",
    "                #mae[r][k][k1] = mean_absolute_error(y[k1], pred)\n",
    "                thresh[r][k][k1] = optimize_thresh(reg, X[k], y[k], X[k1], y[k1], t1_range, 10)\n",
    "                #y_label_true = to_label(y[k1], thresh_accuracy_mae[r][0])\n",
    "                #y_label_pred = to_label(pred, thresh_accuracy_mae[r][0])\n",
    "                #acc[r][k][k1] = accuracy_score(y_label_true, y_label_pred)\n",
    "                #prec[r][k][k1] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                #recl[r][k][k1] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                #f1[r][k][k1] = f1_score(y_label_true, y_label_pred, average = None)  \n",
    "            else:    # train and test on itself\n",
    "                X_tr, X_te, y_tr, y_te = train_test_split(X[k], y[k], test_size = 0.25, random_state = 1)\n",
    "                thresh[r][k][k] = optimize_thresh(reg, X_tr, y_tr, X_te, y_te, t1_range, 10)\n",
    "                #pred = reg.fit(X_tr, y_tr).predict(X_te)\n",
    "                #mae[r][k][k1] = mean_absolute_error(y_te, pred)\n",
    "                #y_label_true = to_label(y_te, thresh_accuracy_mae[r][0])\n",
    "                #y_label_pred = to_label(pred, thresh_accuracy_mae[r][0])\n",
    "                #acc[r][k][k] = accuracy_score(y_label_true, y_label_pred)\n",
    "                #prec[r][k][k] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                #recl[r][k][k] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                #f1[r][k][k] = f1_score(y_label_true, y_label_pred, average = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def print_results(dic, title):\n",
    "    print('#################################')\n",
    "    print('{} results:'.format(title))\n",
    "    for k, v in dic.items():\n",
    "        print(k)\n",
    "        for k1, v1 in v.items():\n",
    "            print(\"training set: {}\".format(k1))\n",
    "            for k2, v2 in v1.items():\n",
    "                print(\"optimal thresholds on {}: {}, {}\".format(k2, np.around(v2[0][0], decimals = 3), np.around(v2[0][1], decimals = 3)))\n",
    "                print(\"optimal accuracy on {}: {}\".format(k2, np.around(v2[1], decimals = 3)))\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AdaBoost': [(array([2., 3.]),\n",
       "   0.8666666666666667,\n",
       "   array([0.95833333, 0.        , 0.84      ]),\n",
       "   array([0.92      , 0.        , 0.97674419]),\n",
       "   array([0.93877551, 0.        , 0.90322581])),\n",
       "  (array([2., 4.]),\n",
       "   0.8933333333333333,\n",
       "   array([0.95833333, 0.81818182, 0.89655172]),\n",
       "   array([1.        , 0.81818182, 0.86666667]),\n",
       "   array([0.9787234 , 0.81818182, 0.88135593])),\n",
       "  (array([2., 3.]),\n",
       "   0.92,\n",
       "   array([0.96153846, 0.        , 0.89795918]),\n",
       "   array([1., 0., 1.]),\n",
       "   array([0.98039216, 0.        , 0.94623656])),\n",
       "  (array([2., 3.]),\n",
       "   0.84,\n",
       "   array([0.91304348, 0.        , 0.82352941]),\n",
       "   array([0.91304348, 0.        , 0.97674419]),\n",
       "   array([0.91304348, 0.        , 0.89361702])),\n",
       "  (array([2., 3.]),\n",
       "   0.8533333333333334,\n",
       "   array([0.83333333, 0.        , 0.88      ]),\n",
       "   array([1.        , 0.        , 0.93617021]),\n",
       "   array([0.90909091, 0.        , 0.90721649])),\n",
       "  (array([2., 3.]),\n",
       "   0.8933333333333333,\n",
       "   array([0.96, 0.  , 0.86]),\n",
       "   array([1., 0., 1.]),\n",
       "   array([0.97959184, 0.        , 0.92473118])),\n",
       "  (array([2., 3.]),\n",
       "   0.9066666666666666,\n",
       "   array([0.96774194, 1.        , 0.86046512]),\n",
       "   array([1.   , 0.125, 1.   ]),\n",
       "   array([0.98360656, 0.22222222, 0.925     ])),\n",
       "  (array([2., 4.]),\n",
       "   0.88,\n",
       "   array([0.95833333, 0.88461538, 0.8       ]),\n",
       "   array([0.95833333, 0.82142857, 0.86956522]),\n",
       "   array([0.95833333, 0.85185185, 0.83333333])),\n",
       "  (array([2., 4.]),\n",
       "   0.76,\n",
       "   array([0.92307692, 0.7       , 0.63157895]),\n",
       "   array([0.82758621, 0.75      , 0.66666667]),\n",
       "   array([0.87272727, 0.72413793, 0.64864865])),\n",
       "  (array([2., 3.]),\n",
       "   0.8266666666666667,\n",
       "   array([0.9047619, 0.5      , 0.82     ]),\n",
       "   array([0.86363636, 0.2       , 0.95348837]),\n",
       "   array([0.88372093, 0.28571429, 0.88172043])),\n",
       "  (array([2., 3.]),\n",
       "   0.8533333333333334,\n",
       "   array([1.        , 0.        , 0.80769231]),\n",
       "   array([0.91666667, 0.        , 0.97674419]),\n",
       "   array([0.95652174, 0.        , 0.88421053])),\n",
       "  (array([2., 3.]),\n",
       "   0.8266666666666667,\n",
       "   array([0.92592593, 0.        , 0.80434783]),\n",
       "   array([0.89285714, 0.        , 0.94871795]),\n",
       "   array([0.90909091, 0.        , 0.87058824])),\n",
       "  (array([2.65, 4.  ]),\n",
       "   0.88,\n",
       "   array([0.92307692, 0.84      , 0.875     ]),\n",
       "   array([0.92307692, 0.84      , 0.875     ]),\n",
       "   array([0.92307692, 0.84      , 0.875     ])),\n",
       "  (array([2., 3.]),\n",
       "   0.8666666666666667,\n",
       "   array([0.92      , 0.25      , 0.89130435]),\n",
       "   array([0.92      , 0.16666667, 0.93181818]),\n",
       "   array([0.92      , 0.2       , 0.91111111])),\n",
       "  (array([2.  , 3.95]),\n",
       "   0.7733333333333333,\n",
       "   array([0.90909091, 0.62962963, 0.80769231]),\n",
       "   array([0.86956522, 0.70833333, 0.75      ]),\n",
       "   array([0.88888889, 0.66666667, 0.77777778])),\n",
       "  (array([2., 3.]),\n",
       "   0.8533333333333334,\n",
       "   array([1.        , 0.        , 0.81632653]),\n",
       "   array([0.92307692, 0.        , 0.97560976]),\n",
       "   array([0.96      , 0.        , 0.88888889])),\n",
       "  (array([2., 3.]),\n",
       "   0.8933333333333333,\n",
       "   array([0.96551724, 0.        , 0.88636364]),\n",
       "   array([1.        , 0.        , 0.95121951]),\n",
       "   array([0.98245614, 0.        , 0.91764706])),\n",
       "  (array([2., 3.]),\n",
       "   0.8933333333333333,\n",
       "   array([1.        , 0.5       , 0.87272727]),\n",
       "   array([0.9       , 0.16666667, 0.97959184]),\n",
       "   array([0.94736842, 0.25      , 0.92307692])),\n",
       "  (array([2., 3.]),\n",
       "   0.8266666666666667,\n",
       "   array([0.83333333, 0.        , 0.82352941]),\n",
       "   array([0.95238095, 0.        , 0.93333333]),\n",
       "   array([0.88888889, 0.        , 0.875     ])),\n",
       "  (array([2., 3.]),\n",
       "   0.8666666666666667,\n",
       "   array([0.96428571, 0.        , 0.80851064]),\n",
       "   array([0.93103448, 0.        , 1.        ]),\n",
       "   array([0.94736842, 0.        , 0.89411765]))],\n",
       " 'MLP': [(array([2.5, 3.8]),\n",
       "   0.8133333333333334,\n",
       "   array([0.92      , 0.66666667, 0.82758621]),\n",
       "   array([0.92, 0.7 , 0.8 ]),\n",
       "   array([0.92      , 0.68292683, 0.81355932])),\n",
       "  (array([2.1 , 3.85]),\n",
       "   0.8533333333333334,\n",
       "   array([0.95833333, 0.70833333, 0.88888889]),\n",
       "   array([1.        , 0.80952381, 0.77419355]),\n",
       "   array([0.9787234 , 0.75555556, 0.82758621])),\n",
       "  (array([2.25, 3.9 ]),\n",
       "   0.7866666666666666,\n",
       "   array([0.95454545, 0.64285714, 0.8       ]),\n",
       "   array([0.84      , 0.75      , 0.76923077]),\n",
       "   array([0.89361702, 0.69230769, 0.78431373])),\n",
       "  (array([2.05, 3.95]),\n",
       "   0.8666666666666667,\n",
       "   array([0.9047619 , 0.8       , 0.91666667]),\n",
       "   array([0.82608696, 0.85714286, 0.91666667]),\n",
       "   array([0.86363636, 0.82758621, 0.91666667])),\n",
       "  (array([2.1, 3.5]),\n",
       "   0.8133333333333334,\n",
       "   array([0.9047619 , 0.76470588, 0.78378378]),\n",
       "   array([0.95      , 0.56521739, 0.90625   ]),\n",
       "   array([0.92682927, 0.65      , 0.84057971])),\n",
       "  (array([2., 3.]),\n",
       "   0.88,\n",
       "   array([1.        , 0.4       , 0.86956522]),\n",
       "   array([1.        , 0.25      , 0.93023256]),\n",
       "   array([1.        , 0.30769231, 0.8988764 ])),\n",
       "  (array([2., 3.]),\n",
       "   0.8533333333333334,\n",
       "   array([0.96551724, 0.2       , 0.85365854]),\n",
       "   array([0.93333333, 0.125     , 0.94594595]),\n",
       "   array([0.94915254, 0.15384615, 0.8974359 ])),\n",
       "  (array([2.15, 3.5 ]),\n",
       "   0.7466666666666667,\n",
       "   array([0.95652174, 0.63157895, 0.66666667]),\n",
       "   array([0.91666667, 0.52173913, 0.78571429]),\n",
       "   array([0.93617021, 0.57142857, 0.72131148])),\n",
       "  (array([2.5 , 3.75]),\n",
       "   0.7466666666666667,\n",
       "   array([0.89655172, 0.7       , 0.61538462]),\n",
       "   array([0.89655172, 0.53846154, 0.8       ]),\n",
       "   array([0.89655172, 0.60869565, 0.69565217])),\n",
       "  (array([2., 3.]),\n",
       "   0.8,\n",
       "   array([1.        , 0.27272727, 0.84090909]),\n",
       "   array([0.90909091, 0.3       , 0.86046512]),\n",
       "   array([0.95238095, 0.28571429, 0.85057471])),\n",
       "  (array([2.45, 3.8 ]),\n",
       "   0.8266666666666667,\n",
       "   array([0.95833333, 0.71428571, 0.8       ]),\n",
       "   array([0.95833333, 0.68181818, 0.82758621]),\n",
       "   array([0.95833333, 0.69767442, 0.81355932])),\n",
       "  (array([2., 3.]),\n",
       "   0.7733333333333333,\n",
       "   array([1.        , 0.1       , 0.81395349]),\n",
       "   array([0.78571429, 0.125     , 0.8974359 ]),\n",
       "   array([0.88      , 0.11111111, 0.85365854])),\n",
       "  (array([2., 3.]),\n",
       "   0.84,\n",
       "   array([0.95833333, 0.25      , 0.82978723]),\n",
       "   array([0.92      , 0.11111111, 0.95121951]),\n",
       "   array([0.93877551, 0.15384615, 0.88636364])),\n",
       "  (array([2.2, 4. ]),\n",
       "   0.8,\n",
       "   array([0.88461538, 0.66666667, 0.84      ]),\n",
       "   array([0.92      , 0.69565217, 0.77777778]),\n",
       "   array([0.90196078, 0.68085106, 0.80769231])),\n",
       "  (array([2.15, 3.95]),\n",
       "   0.8266666666666667,\n",
       "   array([0.95238095, 0.68965517, 0.88      ]),\n",
       "   array([0.86956522, 0.83333333, 0.78571429]),\n",
       "   array([0.90909091, 0.75471698, 0.83018868])),\n",
       "  (array([2., 3.]),\n",
       "   0.8533333333333334,\n",
       "   array([0.96      , 0.        , 0.81632653]),\n",
       "   array([0.92307692, 0.        , 0.97560976]),\n",
       "   array([0.94117647, 0.        , 0.88888889])),\n",
       "  (array([2.15, 3.95]),\n",
       "   0.7866666666666666,\n",
       "   array([0.96296296, 0.64285714, 0.75      ]),\n",
       "   array([0.92857143, 0.75      , 0.65217391]),\n",
       "   array([0.94545455, 0.69230769, 0.69767442])),\n",
       "  (array([2.25, 3.5 ]),\n",
       "   0.8,\n",
       "   array([1.        , 0.83333333, 0.71111111]),\n",
       "   array([0.9       , 0.43478261, 1.        ]),\n",
       "   array([0.94736842, 0.57142857, 0.83116883])),\n",
       "  (array([2., 3.]),\n",
       "   0.8266666666666667,\n",
       "   array([1.        , 0.38461538, 0.88372093]),\n",
       "   array([0.9047619 , 0.55555556, 0.84444444]),\n",
       "   array([0.95      , 0.45454545, 0.86363636])),\n",
       "  (array([2.25, 3.8 ]),\n",
       "   0.7866666666666666,\n",
       "   array([0.96296296, 0.72413793, 0.63157895]),\n",
       "   array([0.89655172, 0.75      , 0.66666667]),\n",
       "   array([0.92857143, 0.73684211, 0.64864865]))],\n",
       " 'Nearest Neighbors': [(array([2., 3.]),\n",
       "   0.7733333333333333,\n",
       "   array([1.        , 0.18181818, 0.82978723]),\n",
       "   array([0.68      , 0.28571429, 0.90697674]),\n",
       "   array([0.80952381, 0.22222222, 0.86666667])),\n",
       "  (array([2.6, 3.8]),\n",
       "   0.7733333333333333,\n",
       "   array([0.91666667, 0.59090909, 0.79310345]),\n",
       "   array([0.95652174, 0.61904762, 0.74193548]),\n",
       "   array([0.93617021, 0.60465116, 0.76666667])),\n",
       "  (array([2.6 , 3.85]),\n",
       "   0.6666666666666666,\n",
       "   array([0.95652174, 0.48275862, 0.60869565]),\n",
       "   array([0.88      , 0.58333333, 0.53846154]),\n",
       "   array([0.91666667, 0.52830189, 0.57142857])),\n",
       "  (array([2., 3.]),\n",
       "   0.8666666666666667,\n",
       "   array([1.  , 0.5 , 0.86]),\n",
       "   array([0.82608696, 0.33333333, 1.        ]),\n",
       "   array([0.9047619 , 0.4       , 0.92473118])),\n",
       "  (array([2., 3.]),\n",
       "   0.8133333333333334,\n",
       "   array([1.        , 0.14285714, 0.8490566 ]),\n",
       "   array([0.75      , 0.125     , 0.95744681]),\n",
       "   array([0.85714286, 0.13333333, 0.9       ])),\n",
       "  (array([2.4 , 3.65]),\n",
       "   0.7066666666666667,\n",
       "   array([1.        , 0.61904762, 0.58823529]),\n",
       "   array([0.83333333, 0.52      , 0.76923077]),\n",
       "   array([0.90909091, 0.56521739, 0.66666667])),\n",
       "  (array([2.6, 3.9]),\n",
       "   0.8666666666666667,\n",
       "   array([0.96666667, 0.85714286, 0.75      ]),\n",
       "   array([0.96666667, 0.72      , 0.9       ]),\n",
       "   array([0.96666667, 0.7826087 , 0.81818182])),\n",
       "  (array([2.6 , 3.95]),\n",
       "   0.7733333333333333,\n",
       "   array([0.90909091, 0.73076923, 0.7037037 ]),\n",
       "   array([0.83333333, 0.67857143, 0.82608696]),\n",
       "   array([0.86956522, 0.7037037 , 0.76      ])),\n",
       "  (array([2.25, 3.85]),\n",
       "   0.64,\n",
       "   array([0.95833333, 0.5       , 0.48      ]),\n",
       "   array([0.79310345, 0.5       , 0.6       ]),\n",
       "   array([0.86792453, 0.5       , 0.53333333])),\n",
       "  (array([2., 3.]),\n",
       "   0.76,\n",
       "   array([1.        , 0.        , 0.78431373]),\n",
       "   array([0.77272727, 0.        , 0.93023256]),\n",
       "   array([0.87179487, 0.        , 0.85106383])),\n",
       "  (array([2., 3.]),\n",
       "   0.7866666666666666,\n",
       "   array([0.95      , 0.18181818, 0.86363636]),\n",
       "   array([0.79166667, 0.25      , 0.88372093]),\n",
       "   array([0.86363636, 0.21052632, 0.87356322])),\n",
       "  (array([2.55, 3.95]),\n",
       "   0.68,\n",
       "   array([1.  , 0.5 , 0.56]),\n",
       "   array([0.85714286, 0.54166667, 0.60869565]),\n",
       "   array([0.92307692, 0.52      , 0.58333333])),\n",
       "  (array([2., 3.]),\n",
       "   0.8133333333333334,\n",
       "   array([0.95238095, 0.28571429, 0.82978723]),\n",
       "   array([0.8       , 0.22222222, 0.95121951]),\n",
       "   array([0.86956522, 0.25      , 0.88636364])),\n",
       "  (array([2.6, 3.7]),\n",
       "   0.72,\n",
       "   array([0.875     , 0.61538462, 0.65789474]),\n",
       "   array([0.84      , 0.34782609, 0.92592593]),\n",
       "   array([0.85714286, 0.44444444, 0.76923077])),\n",
       "  (array([2., 3.]),\n",
       "   0.7733333333333333,\n",
       "   array([0.9375    , 0.        , 0.82692308]),\n",
       "   array([0.65217391, 0.        , 0.95555556]),\n",
       "   array([0.76923077, 0.        , 0.88659794])),\n",
       "  (array([2., 3.]),\n",
       "   0.8266666666666667,\n",
       "   array([1.        , 0.        , 0.80392157]),\n",
       "   array([0.80769231, 0.        , 1.        ]),\n",
       "   array([0.89361702, 0.        , 0.89130435])),\n",
       "  (array([2., 3.]),\n",
       "   0.8266666666666667,\n",
       "   array([0.91666667, 0.14285714, 0.88636364]),\n",
       "   array([0.78571429, 0.16666667, 0.95121951]),\n",
       "   array([0.84615385, 0.15384615, 0.91764706])),\n",
       "  (array([2., 3.]),\n",
       "   0.8266666666666667,\n",
       "   array([1.        , 0.        , 0.89090909]),\n",
       "   array([0.65, 0.  , 1.  ]),\n",
       "   array([0.78787879, 0.        , 0.94230769])),\n",
       "  (array([2., 3.]),\n",
       "   0.8,\n",
       "   array([1.        , 0.16666667, 0.81132075]),\n",
       "   array([0.76190476, 0.11111111, 0.95555556]),\n",
       "   array([0.86486486, 0.13333333, 0.87755102])),\n",
       "  (array([2., 3.]),\n",
       "   0.7466666666666667,\n",
       "   array([0.95      , 0.09090909, 0.81818182]),\n",
       "   array([0.65517241, 0.125     , 0.94736842]),\n",
       "   array([0.7755102 , 0.10526316, 0.87804878]))],\n",
       " 'Random Forest': [(array([2. , 3.8]),\n",
       "   0.7866666666666666,\n",
       "   array([1.        , 0.59259259, 0.82758621]),\n",
       "   array([0.76, 0.8 , 0.8 ]),\n",
       "   array([0.86363636, 0.68085106, 0.81355932])),\n",
       "  (array([2.25, 3.95]),\n",
       "   0.84,\n",
       "   array([0.95833333, 0.69565217, 0.85714286]),\n",
       "   array([1.        , 0.76190476, 0.77419355]),\n",
       "   array([0.9787234 , 0.72727273, 0.81355932])),\n",
       "  (array([2.35, 3.8 ]),\n",
       "   0.8933333333333333,\n",
       "   array([0.96153846, 0.9       , 0.82758621]),\n",
       "   array([1.        , 0.75      , 0.92307692]),\n",
       "   array([0.98039216, 0.81818182, 0.87272727])),\n",
       "  (array([2.  , 3.85]),\n",
       "   0.8133333333333334,\n",
       "   array([0.9       , 0.73333333, 0.84      ]),\n",
       "   array([0.7826087 , 0.81481481, 0.84      ]),\n",
       "   array([0.8372093 , 0.77192982, 0.84      ])),\n",
       "  (array([2.4 , 3.95]),\n",
       "   0.8266666666666667,\n",
       "   array([0.79166667, 0.7826087 , 0.89285714]),\n",
       "   array([0.95      , 0.69230769, 0.86206897]),\n",
       "   array([0.86363636, 0.73469388, 0.87719298])),\n",
       "  (array([2.4 , 3.85]),\n",
       "   0.8533333333333334,\n",
       "   array([0.96      , 0.85      , 0.76666667]),\n",
       "   array([1.        , 0.68      , 0.88461538]),\n",
       "   array([0.97959184, 0.75555556, 0.82142857])),\n",
       "  (array([2.3 , 3.75]),\n",
       "   0.8933333333333333,\n",
       "   array([0.96774194, 0.94736842, 0.76      ]),\n",
       "   array([1.  , 0.72, 0.95]),\n",
       "   array([0.98360656, 0.81818182, 0.84444444])),\n",
       "  (array([2.  , 3.85]),\n",
       "   0.8266666666666667,\n",
       "   array([0.95652174, 0.8       , 0.74074074]),\n",
       "   array([0.91666667, 0.74074074, 0.83333333]),\n",
       "   array([0.93617021, 0.76923077, 0.78431373])),\n",
       "  (array([2.35, 3.7 ]),\n",
       "   0.72,\n",
       "   array([0.89655172, 0.63636364, 0.58333333]),\n",
       "   array([0.89655172, 0.56      , 0.66666667]),\n",
       "   array([0.89655172, 0.59574468, 0.62222222])),\n",
       "  (array([2.55, 3.95]),\n",
       "   0.8933333333333333,\n",
       "   array([0.95652174, 0.89655172, 0.82608696]),\n",
       "   array([1.        , 0.86666667, 0.82608696]),\n",
       "   array([0.97777778, 0.88135593, 0.82608696])),\n",
       "  (array([2., 4.]),\n",
       "   0.84,\n",
       "   array([1.        , 0.7037037 , 0.85185185]),\n",
       "   array([0.875     , 0.82608696, 0.82142857]),\n",
       "   array([0.93333333, 0.76      , 0.83636364])),\n",
       "  (array([2.  , 3.85]),\n",
       "   0.7733333333333333,\n",
       "   array([0.92307692, 0.68421053, 0.7       ]),\n",
       "   array([0.85714286, 0.56521739, 0.875     ]),\n",
       "   array([0.88888889, 0.61904762, 0.77777778])),\n",
       "  (array([2., 4.]),\n",
       "   0.8133333333333334,\n",
       "   array([0.90909091, 0.74074074, 0.80769231]),\n",
       "   array([0.8       , 0.76923077, 0.875     ]),\n",
       "   array([0.85106383, 0.75471698, 0.84      ])),\n",
       "  (array([2.05, 4.  ]),\n",
       "   0.8133333333333334,\n",
       "   array([0.96      , 0.73684211, 0.74193548]),\n",
       "   array([0.96      , 0.60869565, 0.85185185]),\n",
       "   array([0.96      , 0.66666667, 0.79310345])),\n",
       "  (array([2.5 , 3.95]),\n",
       "   0.8266666666666667,\n",
       "   array([0.95454545, 0.68965517, 0.875     ]),\n",
       "   array([0.91304348, 0.83333333, 0.75      ]),\n",
       "   array([0.93333333, 0.75471698, 0.80769231])),\n",
       "  (array([2.3, 3.9]),\n",
       "   0.8533333333333334,\n",
       "   array([1.        , 0.68965517, 0.90909091]),\n",
       "   array([0.92307692, 0.95238095, 0.71428571]),\n",
       "   array([0.96, 0.8 , 0.8 ])),\n",
       "  (array([2.35, 3.8 ]),\n",
       "   0.8533333333333334,\n",
       "   array([0.93333333, 0.85      , 0.76      ]),\n",
       "   array([1.        , 0.70833333, 0.82608696]),\n",
       "   array([0.96551724, 0.77272727, 0.79166667])),\n",
       "  (array([2.3, 3.4]),\n",
       "   0.84,\n",
       "   array([1.        , 0.90909091, 0.75555556]),\n",
       "   array([0.95      , 0.47619048, 1.        ]),\n",
       "   array([0.97435897, 0.625     , 0.86075949])),\n",
       "  (array([2., 4.]),\n",
       "   0.84,\n",
       "   array([0.94736842, 0.79310345, 0.81481481]),\n",
       "   array([0.85714286, 0.82142857, 0.84615385]),\n",
       "   array([0.9       , 0.80701754, 0.83018868])),\n",
       "  (array([2.55, 4.  ]),\n",
       "   0.8133333333333334,\n",
       "   array([0.96153846, 0.7027027 , 0.83333333]),\n",
       "   array([0.86206897, 0.89655172, 0.58823529]),\n",
       "   array([0.90909091, 0.78787879, 0.68965517]))],\n",
       " 'SVM': [(array([2., 3.]),\n",
       "   0.84,\n",
       "   array([1.        , 0.3       , 0.89130435]),\n",
       "   array([0.76      , 0.42857143, 0.95348837]),\n",
       "   array([0.86363636, 0.35294118, 0.92134831])),\n",
       "  (array([2.25, 3.8 ]),\n",
       "   0.88,\n",
       "   array([0.95833333, 0.73076923, 0.96      ]),\n",
       "   array([1.        , 0.9047619 , 0.77419355]),\n",
       "   array([0.9787234 , 0.80851064, 0.85714286])),\n",
       "  (array([2.25, 4.  ]),\n",
       "   0.8266666666666667,\n",
       "   array([0.95833333, 0.76      , 0.76923077]),\n",
       "   array([0.92      , 0.73076923, 0.83333333]),\n",
       "   array([0.93877551, 0.74509804, 0.8       ])),\n",
       "  (array([2., 3.]),\n",
       "   0.84,\n",
       "   array([0.94444444, 0.38461538, 0.93181818]),\n",
       "   array([0.73913043, 0.55555556, 0.95348837]),\n",
       "   array([0.82926829, 0.45454545, 0.94252874])),\n",
       "  (array([2.55, 3.55]),\n",
       "   0.7733333333333333,\n",
       "   array([0.83333333, 0.6875    , 0.77142857]),\n",
       "   array([1.        , 0.47826087, 0.84375   ]),\n",
       "   array([0.90909091, 0.56410256, 0.80597015])),\n",
       "  (array([2.3 , 3.95]),\n",
       "   0.8533333333333334,\n",
       "   array([0.96      , 0.86363636, 0.75      ]),\n",
       "   array([1.       , 0.7037037, 0.875    ]),\n",
       "   array([0.97959184, 0.7755102 , 0.80769231])),\n",
       "  (array([2., 3.]),\n",
       "   0.8933333333333333,\n",
       "   array([1.   , 0.5  , 0.875]),\n",
       "   array([0.96666667, 0.375     , 0.94594595]),\n",
       "   array([0.98305085, 0.42857143, 0.90909091])),\n",
       "  (array([2.4, 3.5]),\n",
       "   0.7733333333333333,\n",
       "   array([0.95833333, 0.76923077, 0.65789474]),\n",
       "   array([0.95833333, 0.43478261, 0.89285714]),\n",
       "   array([0.95833333, 0.55555556, 0.75757576])),\n",
       "  (array([2.4 , 3.85]),\n",
       "   0.7466666666666667,\n",
       "   array([0.92857143, 0.65384615, 0.61904762]),\n",
       "   array([0.89655172, 0.65384615, 0.65      ]),\n",
       "   array([0.9122807 , 0.65384615, 0.63414634])),\n",
       "  (array([2.05, 3.05]),\n",
       "   0.7733333333333333,\n",
       "   array([1.        , 0.36363636, 0.77272727]),\n",
       "   array([0.90909091, 0.28571429, 0.87179487]),\n",
       "   array([0.95238095, 0.32      , 0.81927711])),\n",
       "  (array([2., 3.]),\n",
       "   0.7866666666666666,\n",
       "   array([1.        , 0.16666667, 0.86363636]),\n",
       "   array([0.79166667, 0.25      , 0.88372093]),\n",
       "   array([0.88372093, 0.2       , 0.87356322])),\n",
       "  (array([2.05, 3.9 ]),\n",
       "   0.7733333333333333,\n",
       "   array([1.        , 0.625     , 0.71428571]),\n",
       "   array([0.82142857, 0.65217391, 0.83333333]),\n",
       "   array([0.90196078, 0.63829787, 0.76923077])),\n",
       "  (array([2., 3.]),\n",
       "   0.8133333333333334,\n",
       "   array([0.95652174, 0.16666667, 0.82608696]),\n",
       "   array([0.88      , 0.11111111, 0.92682927]),\n",
       "   array([0.91666667, 0.13333333, 0.87356322])),\n",
       "  (array([2.45, 3.95]),\n",
       "   0.7733333333333333,\n",
       "   array([0.88888889, 0.65217391, 0.76      ]),\n",
       "   array([0.96      , 0.65217391, 0.7037037 ]),\n",
       "   array([0.92307692, 0.65217391, 0.73076923])),\n",
       "  (array([2.45, 4.  ]),\n",
       "   0.8666666666666667,\n",
       "   array([0.92      , 0.86956522, 0.81481481]),\n",
       "   array([1.        , 0.76923077, 0.84615385]),\n",
       "   array([0.95833333, 0.81632653, 0.83018868])),\n",
       "  (array([2., 3.]),\n",
       "   0.8,\n",
       "   array([1.        , 0.125     , 0.82222222]),\n",
       "   array([0.84615385, 0.125     , 0.90243902]),\n",
       "   array([0.91666667, 0.125     , 0.86046512])),\n",
       "  (array([2.25, 4.  ]),\n",
       "   0.8533333333333334,\n",
       "   array([0.96551724, 0.79166667, 0.77272727]),\n",
       "   array([1.        , 0.76      , 0.77272727]),\n",
       "   array([0.98245614, 0.7755102 , 0.77272727])),\n",
       "  (array([2.45, 4.  ]),\n",
       "   0.8266666666666667,\n",
       "   array([1.        , 0.73076923, 0.80645161]),\n",
       "   array([0.9       , 0.76      , 0.83333333]),\n",
       "   array([0.94736842, 0.74509804, 0.81967213])),\n",
       "  (array([2., 3.]),\n",
       "   0.7866666666666666,\n",
       "   array([1.        , 0.28571429, 0.86363636]),\n",
       "   array([0.80952381, 0.44444444, 0.84444444]),\n",
       "   array([0.89473684, 0.34782609, 0.85393258])),\n",
       "  (array([2.4, 4. ]),\n",
       "   0.8,\n",
       "   array([0.96296296, 0.74193548, 0.64705882]),\n",
       "   array([0.89655172, 0.79310345, 0.64705882]),\n",
       "   array([0.92857143, 0.76666667, 0.64705882]))]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh_scores_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "acc = {}\n",
    "prec = {}\n",
    "recl = {}\n",
    "f1 = {}\n",
    "for r, reg in best_regressors_mse.items():\n",
    "    acc[r] = {}\n",
    "    prec[r] = {}\n",
    "    recl[r] = {} \n",
    "    f1[r] = {}    \n",
    "    for k in X.keys():\n",
    "        acc[r][k] = {}\n",
    "        prec[r][k] = {}\n",
    "        recl[r][k] = {} \n",
    "        f1[r][k] = {}\n",
    "        for k1 in X.keys():\n",
    "            if k1 != k: # train and test on other datasets\n",
    "                pred = reg.fit(X[k], y[k]).predict(X[k1])\n",
    "                y_label_true = to_label(y[k1], avg_thresh_scores_mse[r]['thresholds'])\n",
    "                y_label_pred = to_label(pred, avg_thresh_scores_mse[r]['thresholds'])\n",
    "                acc[r][k][k1] = accuracy_score(y_label_true, y_label_pred)\n",
    "                prec[r][k][k1] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                recl[r][k][k1] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                f1[r][k][k1] = f1_score(y_label_true, y_label_pred, average = None)  \n",
    "            else:    # train and test on itself\n",
    "                X_tr, X_te, y_tr, y_te = train_test_split(X[k], y[k], test_size = 0.25, random_state = 1)\n",
    "                pred = reg.fit(X_tr, y_tr).predict(X_te)\n",
    "                y_label_true = to_label(y_te, avg_thresh_scores_mse[r]['thresholds'])\n",
    "                y_label_pred = to_label(pred, avg_thresh_scores_mse[r]['thresholds'])\n",
    "                acc[r][k][k] = accuracy_score(y_label_true, y_label_pred)\n",
    "                prec[r][k][k] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                recl[r][k][k] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                f1[r][k][k] = f1_score(y_label_true, y_label_pred, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_results(dic, title):\n",
    "    print('#################################')\n",
    "    print('{} results:'.format(title))\n",
    "    for k, v in dic.items():\n",
    "        print(k)\n",
    "        for k1, v1 in v.items():\n",
    "            print(\"training set: {}\".format(k1))\n",
    "            for k2, v2 in v1.items():\n",
    "                print(\"{} on {}: {}\".format(title, k2, np.around(v2, decimals = 3)))\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################\n",
      "accuracy results:\n",
      "AdaBoost\n",
      "training set: s2\n",
      "accuracy on s2: 0.64\n",
      "accuracy on s6: 0.78\n",
      "accuracy on px: 0.73\n",
      "training set: s6\n",
      "accuracy on s2: 0.8\n",
      "accuracy on s6: 0.84\n",
      "accuracy on px: 0.65\n",
      "training set: px\n",
      "accuracy on s2: 0.76\n",
      "accuracy on s6: 0.67\n",
      "accuracy on px: 0.92\n",
      "\n",
      "MLP\n",
      "training set: s2\n",
      "accuracy on s2: 0.72\n",
      "accuracy on s6: 0.77\n",
      "accuracy on px: 0.77\n",
      "training set: s6\n",
      "accuracy on s2: 0.83\n",
      "accuracy on s6: 0.8\n",
      "accuracy on px: 0.78\n",
      "training set: px\n",
      "accuracy on s2: 0.77\n",
      "accuracy on s6: 0.67\n",
      "accuracy on px: 0.84\n",
      "\n",
      "Nearest Neighbors\n",
      "training set: s2\n",
      "accuracy on s2: 0.56\n",
      "accuracy on s6: 0.71\n",
      "accuracy on px: 0.69\n",
      "training set: s6\n",
      "accuracy on s2: 0.72\n",
      "accuracy on s6: 0.64\n",
      "accuracy on px: 0.73\n",
      "training set: px\n",
      "accuracy on s2: 0.68\n",
      "accuracy on s6: 0.6\n",
      "accuracy on px: 0.8\n",
      "\n",
      "Random Forest\n",
      "training set: s2\n",
      "accuracy on s2: 0.76\n",
      "accuracy on s6: 0.78\n",
      "accuracy on px: 0.75\n",
      "training set: s6\n",
      "accuracy on s2: 0.86\n",
      "accuracy on s6: 0.96\n",
      "accuracy on px: 0.71\n",
      "training set: px\n",
      "accuracy on s2: 0.8\n",
      "accuracy on s6: 0.72\n",
      "accuracy on px: 0.88\n",
      "\n",
      "SVM\n",
      "training set: s2\n",
      "accuracy on s2: 0.6\n",
      "accuracy on s6: 0.81\n",
      "accuracy on px: 0.79\n",
      "training set: s6\n",
      "accuracy on s2: 0.82\n",
      "accuracy on s6: 0.72\n",
      "accuracy on px: 0.79\n",
      "training set: px\n",
      "accuracy on s2: 0.75\n",
      "accuracy on s6: 0.69\n",
      "accuracy on px: 0.8\n",
      "\n",
      "\n",
      "#################################\n",
      "precision results:\n",
      "AdaBoost\n",
      "training set: s2\n",
      "precision on s2: [1.  0.  0.4]\n",
      "precision on s6: [0.905 0.75  0.685]\n",
      "precision on px: [0.643 0.467 0.842]\n",
      "training set: s6\n",
      "precision on s2: [0.943 1.    0.714]\n",
      "precision on s6: [1.   0.75 0.75]\n",
      "precision on px: [0.5 0.  0.8]\n",
      "training set: px\n",
      "precision on s2: [1.    0.429 0.774]\n",
      "precision on s6: [1.    0.312 0.761]\n",
      "precision on px: [1.    1.    0.889]\n",
      "\n",
      "MLP\n",
      "training set: s2\n",
      "precision on s2: [1.    0.8   0.455]\n",
      "precision on s6: [0.925 0.6   0.7  ]\n",
      "precision on px: [0.875 0.59  0.889]\n",
      "training set: s6\n",
      "precision on s2: [1.    0.857 0.717]\n",
      "precision on s6: [1.    1.    0.583]\n",
      "precision on px: [0.789 0.611 0.911]\n",
      "training set: px\n",
      "precision on s2: [1.    0.583 0.745]\n",
      "precision on s6: [0.933 0.393 0.667]\n",
      "precision on px: [1.    0.6   0.875]\n",
      "\n",
      "Nearest Neighbors\n",
      "training set: s2\n",
      "precision on s2: [1.  0.  0.4]\n",
      "precision on s6: [1.    0.381 0.686]\n",
      "precision on px: [0.947 0.267 0.712]\n",
      "training set: s6\n",
      "precision on s2: [1.    0.2   0.661]\n",
      "precision on s6: [1.    0.429 0.643]\n",
      "precision on px: [0.84  0.4   0.767]\n",
      "training set: px\n",
      "precision on s2: [1.    0.214 0.667]\n",
      "precision on s6: [1.    0.217 0.593]\n",
      "precision on px: [1.    0.    0.789]\n",
      "\n",
      "Random Forest\n",
      "training set: s2\n",
      "precision on s2: [1.    1.    0.333]\n",
      "precision on s6: [0.905 0.633 0.75 ]\n",
      "precision on px: [0.643 0.719 0.85 ]\n",
      "training set: s6\n",
      "precision on s2: [1.    0.88  0.738]\n",
      "precision on s6: [1.    1.    0.875]\n",
      "precision on px: [0.567 0.667 0.865]\n",
      "training set: px\n",
      "precision on s2: [1.    0.667 0.794]\n",
      "precision on s6: [1.    0.528 0.676]\n",
      "precision on px: [1.    0.75  0.923]\n",
      "\n",
      "SVM\n",
      "training set: s2\n",
      "precision on s2: [1.    0.5   0.385]\n",
      "precision on s6: [0.974 0.7   0.714]\n",
      "precision on px: [0.909 0.643 0.82 ]\n",
      "training set: s6\n",
      "precision on s2: [1.    0.8   0.717]\n",
      "precision on s6: [1.    0.667 0.583]\n",
      "precision on px: [0.84  0.655 0.848]\n",
      "training set: px\n",
      "precision on s2: [1.    0.55  0.686]\n",
      "precision on s6: [1.    0.417 0.63 ]\n",
      "precision on px: [1.    0.5   0.824]\n",
      "\n",
      "\n",
      "#################################\n",
      "recall results:\n",
      "AdaBoost\n",
      "training set: s2\n",
      "recall on s2: [1. 0. 1.]\n",
      "recall on s6: [0.95  0.143 0.949]\n",
      "recall on px: [0.72  0.35  0.873]\n",
      "training set: s6\n",
      "recall on s2: [1.    0.095 0.978]\n",
      "recall on s6: [1.  0.5 0.9]\n",
      "recall on px: [0.68  0.    0.873]\n",
      "training set: px\n",
      "recall on s2: [0.788 0.429 0.891]\n",
      "recall on s6: [0.55  0.476 0.897]\n",
      "recall on px: [1.    0.333 1.   ]\n",
      "\n",
      "MLP\n",
      "training set: s2\n",
      "recall on s2: [0.9 0.4 1. ]\n",
      "recall on s6: [0.925 0.444 0.848]\n",
      "recall on px: [0.56  0.821 0.851]\n",
      "training set: s6\n",
      "recall on s2: [1.    0.444 0.95 ]\n",
      "recall on s6: [1.    0.444 1.   ]\n",
      "recall on px: [0.6   0.786 0.872]\n",
      "training set: px\n",
      "recall on s2: [0.758 0.519 0.95 ]\n",
      "recall on s6: [0.7   0.407 0.848]\n",
      "recall on px: [0.667 0.6   1.   ]\n",
      "\n",
      "Nearest Neighbors\n",
      "training set: s2\n",
      "recall on s2: [0.8 0.  1. ]\n",
      "recall on s6: [0.7   0.364 0.921]\n",
      "recall on px: [0.72  0.182 0.887]\n",
      "training set: s6\n",
      "recall on s2: [0.939 0.091 0.867]\n",
      "recall on s6: [0.444 0.429 1.   ]\n",
      "recall on px: [0.84  0.273 0.868]\n",
      "training set: px\n",
      "recall on s2: [0.697 0.136 0.933]\n",
      "recall on s6: [0.575 0.227 0.842]\n",
      "recall on px: [0.833 0.    1.   ]\n",
      "\n",
      "Random Forest\n",
      "training set: s2\n",
      "recall on s2: [1.  0.5 1. ]\n",
      "recall on s6: [0.95  0.633 0.7  ]\n",
      "recall on px: [0.72  0.639 0.872]\n",
      "training set: s6\n",
      "recall on s2: [1.    0.667 0.912]\n",
      "recall on s6: [1.    0.889 1.   ]\n",
      "recall on px: [0.68  0.611 0.821]\n",
      "training set: px\n",
      "recall on s2: [0.818 0.788 0.794]\n",
      "recall on s6: [0.75  0.633 0.767]\n",
      "recall on px: [0.667 0.857 1.   ]\n",
      "\n",
      "SVM\n",
      "training set: s2\n",
      "recall on s2: [0.8 0.2 1. ]\n",
      "recall on s6: [0.925 0.519 0.909]\n",
      "recall on px: [0.8   0.643 0.872]\n",
      "training set: s6\n",
      "recall on s2: [0.97  0.444 0.95 ]\n",
      "recall on s6: [0.778 0.444 1.   ]\n",
      "recall on px: [0.84  0.679 0.83 ]\n",
      "training set: px\n",
      "recall on s2: [0.879 0.407 0.875]\n",
      "recall on s6: [0.75  0.37  0.879]\n",
      "recall on px: [0.667 0.4   1.   ]\n",
      "\n",
      "\n",
      "#################################\n",
      "f1_score results:\n",
      "AdaBoost\n",
      "training set: s2\n",
      "f1_score on s2: [1.    0.    0.571]\n",
      "f1_score on s6: [0.927 0.24  0.796]\n",
      "f1_score on px: [0.679 0.4   0.857]\n",
      "training set: s6\n",
      "f1_score on s2: [0.971 0.174 0.826]\n",
      "f1_score on s6: [1.    0.6   0.818]\n",
      "f1_score on px: [0.576 0.    0.835]\n",
      "training set: px\n",
      "f1_score on s2: [0.881 0.429 0.828]\n",
      "f1_score on s6: [0.71  0.377 0.824]\n",
      "f1_score on px: [1.    0.5   0.941]\n",
      "\n",
      "MLP\n",
      "training set: s2\n",
      "f1_score on s2: [0.947 0.533 0.625]\n",
      "f1_score on s6: [0.925 0.511 0.767]\n",
      "f1_score on px: [0.683 0.687 0.87 ]\n",
      "training set: s6\n",
      "f1_score on s2: [1.    0.585 0.817]\n",
      "f1_score on s6: [1.    0.615 0.737]\n",
      "f1_score on px: [0.682 0.688 0.891]\n",
      "training set: px\n",
      "f1_score on s2: [0.862 0.549 0.835]\n",
      "f1_score on s6: [0.8   0.4   0.747]\n",
      "f1_score on px: [0.8   0.6   0.933]\n",
      "\n",
      "Nearest Neighbors\n",
      "training set: s2\n",
      "f1_score on s2: [0.889 0.    0.571]\n",
      "f1_score on s6: [0.824 0.372 0.787]\n",
      "f1_score on px: [0.818 0.216 0.79 ]\n",
      "training set: s6\n",
      "f1_score on s2: [0.969 0.125 0.75 ]\n",
      "f1_score on s6: [0.615 0.429 0.783]\n",
      "f1_score on px: [0.84  0.324 0.814]\n",
      "training set: px\n",
      "f1_score on s2: [0.821 0.167 0.778]\n",
      "f1_score on s6: [0.73  0.222 0.696]\n",
      "f1_score on px: [0.909 0.    0.882]\n",
      "\n",
      "Random Forest\n",
      "training set: s2\n",
      "f1_score on s2: [1.    0.667 0.5  ]\n",
      "f1_score on s6: [0.927 0.633 0.724]\n",
      "f1_score on px: [0.679 0.676 0.861]\n",
      "training set: s6\n",
      "f1_score on s2: [1.    0.759 0.816]\n",
      "f1_score on s6: [1.    0.941 0.933]\n",
      "f1_score on px: [0.618 0.638 0.842]\n",
      "training set: px\n",
      "f1_score on s2: [0.9   0.722 0.794]\n",
      "f1_score on s6: [0.857 0.576 0.719]\n",
      "f1_score on px: [0.8  0.8  0.96]\n",
      "\n",
      "SVM\n",
      "training set: s2\n",
      "f1_score on s2: [0.889 0.286 0.556]\n",
      "f1_score on s6: [0.949 0.596 0.8  ]\n",
      "f1_score on px: [0.851 0.643 0.845]\n",
      "training set: s6\n",
      "f1_score on s2: [0.985 0.571 0.817]\n",
      "f1_score on s6: [0.875 0.533 0.737]\n",
      "f1_score on px: [0.84  0.667 0.839]\n",
      "training set: px\n",
      "f1_score on s2: [0.935 0.468 0.769]\n",
      "f1_score on s6: [0.857 0.392 0.734]\n",
      "f1_score on px: [0.8   0.444 0.903]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_results(acc, 'accuracy')\n",
    "print_results(prec, 'precision')\n",
    "print_results(recl, 'recall')\n",
    "print_results(f1, 'f1_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: object of type <class 'float'> cannot be safely interpreted as an integer.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADsBJREFUeJzt23GonXd9x/H3x1xMUaFN2kRr0+xW\nWhjpBoqHFtkGnbVtOtAU7R/p/jBslfwx+8cUwUg3aqt/tN2kIrqNoEIQZusqYkBGia2FMUbtSduh\nmcZco9JrS42kFLpiS+Z3f9yn2/ldzu29uc+59+TW9wsO53l+v+95zveXA/nc53nOSVUhSdKr3jDt\nBiRJ5xaDQZLUMBgkSQ2DQZLUMBgkSQ2DQZLUMBgkSQ2DQZLUMBgkSY2ZaTewGhdddFHNzs5Ouw1J\n2lCOHj3666ratlzdhgyG2dlZhsPhtNuQpA0lyS9WUuelJElSw2CQJDUMBklSw2CQJDUMBklSw2CQ\nJDUMBklSw2CQJDUMBklSw2CQJDUMBklSw2CQJDUMBklSw2CQJDUMBklSw2CQJDUMBklSw2CQJDUM\nBklSw2CQJDUMBklSw2CQJDUMBklSw2CQJDUmEgxJdic5nmQuyYEx85uTPNDNP5ZkdtH8ziQvJvnE\nJPqRJK1e72BIsgn4EnAjsAu4JcmuRWW3As9X1eXAfcA9i+bvA/61by+SpP4mccZwFTBXVSer6hXg\nfmDPopo9wKFu+0Hg2iQBSHITcBI4NoFeJEk9TSIYLgGeHtmf78bG1lTVGeAF4MIkbwY+Cdw5gT4k\nSRMwiWDImLFaYc2dwH1V9eKyb5LsTzJMMjx16tQq2pQkrcTMBI4xD1w6sr8DeGaJmvkkM8D5wGng\nauDmJPcCFwC/TfKbqvri4jepqoPAQYDBYLA4eCRJEzKJYHgcuCLJZcAvgb3Any+qOQzsA/4DuBl4\npKoK+JNXC5J8GnhxXChIktZP72CoqjNJbgMeAjYBX62qY0nuAoZVdRj4CvC1JHMsnCns7fu+kqS1\nkYU/3DeWwWBQw+Fw2m1I0oaS5GhVDZar85fPkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSG\nwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJ\nahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqTGRIIhye4k\nx5PMJTkwZn5zkge6+ceSzHbj1yU5muQH3fN7J9GPJGn1egdDkk3Al4AbgV3ALUl2LSq7FXi+qi4H\n7gPu6cZ/Dby/qv4Q2Ad8rW8/kqR+JnHGcBUwV1Unq+oV4H5gz6KaPcChbvtB4Nokqaonq+qZbvwY\ncF6SzRPoSZK0SpMIhkuAp0f257uxsTVVdQZ4AbhwUc2HgCer6uUJ9CRJWqWZCRwjY8bqbGqSXMnC\n5aXrl3yTZD+wH2Dnzp1n36UkaUUmccYwD1w6sr8DeGapmiQzwPnA6W5/B/At4MNV9dOl3qSqDlbV\noKoG27Ztm0DbkqRxJhEMjwNXJLksyRuBvcDhRTWHWbi5DHAz8EhVVZILgO8An6qqf59AL5KknnoH\nQ3fP4DbgIeBHwDeq6liSu5J8oCv7CnBhkjng48CrX2m9Dbgc+NskT3WP7X17kiStXqoW3w449w0G\ngxoOh9NuQ5I2lCRHq2qwXJ2/fJYkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAk\nNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwG\nSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVJjIsGQZHeS40nmkhwYM785yQPd\n/GNJZkfmPtWNH09ywyT6kSStXu9gSLIJ+BJwI7ALuCXJrkVltwLPV9XlwH3APd1rdwF7gSuB3cA/\ndMeTJE3JJM4YrgLmqupkVb0C3A/sWVSzBzjUbT8IXJsk3fj9VfVyVf0MmOuOJ0makkkEwyXA0yP7\n893Y2JqqOgO8AFy4wtdKktbRJIIhY8ZqhTUree3CAZL9SYZJhqdOnTrLFiVJKzWJYJgHLh3Z3wE8\ns1RNkhngfOD0Cl8LQFUdrKpBVQ22bds2gbYlSeNMIhgeB65IclmSN7JwM/nwoprDwL5u+2bgkaqq\nbnxv962ly4ArgO9PoCdJ0irN9D1AVZ1JchvwELAJ+GpVHUtyFzCsqsPAV4CvJZlj4Uxhb/faY0m+\nAfwXcAb4aFX9T9+eJEmrl4U/3DeWwWBQw+Fw2m1I0oaS5GhVDZar85fPkqSGwSBJahgMkqSGwSBJ\nahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgM\nkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSG\nwSBJahgMkqRGr2BIsjXJkSQnuuctS9Tt62pOJNnXjb0pyXeS/DjJsSR39+lFkjQZfc8YDgAPV9UV\nwMPdfiPJVuAO4GrgKuCOkQD5+6r6feBdwB8lubFnP5KknvoGwx7gULd9CLhpTM0NwJGqOl1VzwNH\ngN1V9VJVfQ+gql4BngB29OxHktRT32B4a1U9C9A9bx9Tcwnw9Mj+fDf2f5JcALyfhbMOSdIUzSxX\nkOS7wNvGTN2+wvfImLEaOf4M8HXgC1V18jX62A/sB9i5c+cK31qSdLaWDYaqet9Sc0meS3JxVT2b\n5GLgV2PK5oFrRvZ3AI+O7B8ETlTV55fp42BXy2AwqNeqlSStXt9LSYeBfd32PuDbY2oeAq5PsqW7\n6Xx9N0aSzwLnA3/dsw9J0oT0DYa7geuSnACu6/ZJMkjyZYCqOg18Bni8e9xVVaeT7GDhctQu4Ikk\nTyX5SM9+JEk9pWrjXZUZDAY1HA6n3YYkbShJjlbVYLk6f/ksSWoYDJKkhsEgSWoYDJKkhsEgSWoY\nDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKk\nhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkRq9g\nSLI1yZEkJ7rnLUvU7etqTiTZN2b+cJIf9ulFkjQZfc8YDgAPV9UVwMPdfiPJVuAO4GrgKuCO0QBJ\n8kHgxZ59SJImpG8w7AEOdduHgJvG1NwAHKmq01X1PHAE2A2Q5C3Ax4HP9uxDkjQhfYPhrVX1LED3\nvH1MzSXA0yP7890YwGeAzwEv9exDkjQhM8sVJPku8LYxU7ev8D0yZqySvBO4vKo+lmR2BX3sB/YD\n7Ny5c4VvLUk6W8sGQ1W9b6m5JM8lubiqnk1yMfCrMWXzwDUj+zuAR4H3AO9O8vOuj+1JHq2qaxij\nqg4CBwEGg0Et17ckaXX6Xko6DLz6LaN9wLfH1DwEXJ9kS3fT+Xrgoar6x6p6e1XNAn8M/GSpUJAk\nrZ++wXA3cF2SE8B13T5JBkm+DFBVp1m4l/B497irG5MknYNStfGuygwGgxoOh9NuQ5I2lCRHq2qw\nXJ2/fJYkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLD\nYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAk\nNVJV0+7hrCU5Bfxi2n2cpYuAX0+7iXXmmn83uOaN4/eqattyRRsyGDaiJMOqGky7j/Xkmn83uObX\nHy8lSZIaBoMkqWEwrJ+D025gClzz7wbX/DrjPQZJUsMzBklSw2CYoCRbkxxJcqJ73rJE3b6u5kSS\nfWPmDyf54dp33F+fNSd5U5LvJPlxkmNJ7l7f7s9Okt1JjieZS3JgzPzmJA90848lmR2Z+1Q3fjzJ\nDevZdx+rXXOS65IcTfKD7vm96937avT5jLv5nUleTPKJ9ep5TVSVjwk9gHuBA932AeCeMTVbgZPd\n85Zue8vI/AeBfwZ+OO31rPWagTcBf9rVvBH4N+DGaa9piXVuAn4KvKPr9T+BXYtq/gr4p257L/BA\nt72rq98MXNYdZ9O017TGa34X8PZu+w+AX057PWu53pH5bwL/Anxi2uvp8/CMYbL2AIe67UPATWNq\nbgCOVNXpqnoeOALsBkjyFuDjwGfXoddJWfWaq+qlqvoeQFW9AjwB7FiHnlfjKmCuqk52vd7PwtpH\njf5bPAhcmyTd+P1V9XJV/QyY6453rlv1mqvqyap6phs/BpyXZPO6dL16fT5jktzEwh89x9ap3zVj\nMEzWW6vqWYDuefuYmkuAp0f257sxgM8AnwNeWssmJ6zvmgFIcgHwfuDhNeqzr2XXMFpTVWeAF4AL\nV/jac1GfNY/6EPBkVb28Rn1OyqrXm+TNwCeBO9ehzzU3M+0GNpok3wXeNmbq9pUeYsxYJXkncHlV\nfWzxdctpW6s1jxx/Bvg68IWqOnn2Ha6L11zDMjUree25qM+aFyaTK4F7gOsn2Nda6bPeO4H7qurF\n7gRiQzMYzlJVvW+puSTPJbm4qp5NcjHwqzFl88A1I/s7gEeB9wDvTvJzFj6X7UkeraprmLI1XPOr\nDgInqurzE2h3rcwDl47s7wCeWaJmvgu784HTK3ztuajPmkmyA/gW8OGq+unat9tbn/VeDdyc5F7g\nAuC3SX5TVV9c+7bXwLRvcryeHsDf0d6IvXdMzVbgZyzcfN3SbW9dVDPLxrn53GvNLNxP+Sbwhmmv\nZZl1zrBw/fgy/v/G5JWLaj5Ke2PyG932lbQ3n0+yMW4+91nzBV39h6a9jvVY76KaT7PBbz5PvYHX\n04OFa6sPAye651f/8xsAXx6p+0sWbkDOAX8x5jgbKRhWvWYW/iIr4EfAU93jI9Ne02us9c+An7Dw\nzZXbu7G7gA902+ex8I2UOeD7wDtGXnt797rjnKPfvJrkmoG/Af575HN9Ctg+7fWs5Wc8cowNHwz+\n8lmS1PBbSZKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWr8L4G+I6VKUcyzAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.linspace(1, 5, 0.025), np.linspace(1, 5, 0.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VOXZ//HPRUAFpS5AlQokam0F\nF1AQtSp1oa1bXaq12tSqTytFaSnqU5daF1Tq477+3FDrQlp3K6KiqFhtVWxQRBQfH1tBUSuLC7Iv\nuX5/3CdhGGYmZ5I5M5PM9/16zSuznDnnyiQ5V869XLe5OyIiIgAdSh2AiIiUDyUFERFpoqQgIiJN\nlBRERKSJkoKIiDRRUhARkSZKCiIi0kRJQUREmigpiIhIk46lDiBf3bt395qamlKHISLSpkydOnW+\nu/dobrs2lxRqamqor68vdRgiIm2Kmc2Os52aj0REpImSgoiINFFSEBGRJkoKIiLSRElBRESaJJoU\nzGyWmb1pZtPMbJ0hQxZcZ2bvmdl0M9slyXhERCS3YgxJ3dfd52d57UBg2+i2G3BT9FVEREqg1M1H\nhwF3e/AKsImZ9SxxTCIiZWXlSnj33eIcK+mk4MDTZjbVzIZleH1L4MOUx3Oi59ZiZsPMrN7M6ufN\nm5dQqCIi5ef112HwYNh3X1i8OPnjJZ0U9nT3XQjNRCPMbEja65bhPb7OE+63uvsgdx/Uo0ezs7RF\nRNq8Zcvg7LNh113hk0/g+uthww2TP26ifQru/nH0da6ZPQIMBl5I2WQO0DvlcS/g4yRjEhFpCw4/\nHJ56Ck48Ea68EjbdtDjHTexKwcw2NLOujfeB7wMz0jYbD/w8GoW0O/Clu3+SVEwiIuXsq6/CFQLA\nWWfB00/DHXcULyFAss1HmwN/N7M3gFeBx919opkNN7Ph0TZPAP8G3gPGAqckGI+ISNl66inYYQe4\n6KLweJ994HvfK34ciTUfufu/gf4Znr855b4DI5KKQUSk3H32GZx2Gtx1F2y3HRx8cGnjKfWQVBGR\nivXss9CvH9TVwTnnhJFG3/lOaWNqc+spiIi0F1//Omy1FUycCAMGlDqaQFcKIiJF4g533gkjR4bH\nO+4IL71UPgkBlBRERIri/ffhBz8IQ0ynTYOlS8Pzlmm2VgkpKYiIJGj1arjuujCy6OWX4cYb4fnn\noXPnUkeWmZKCiEiC5s+H885ewXcbJvPWompOvrSGDn+pK3VYWSkpiEjbVFcHNTXQoUP4Wlc+J9qV\nK0PfQUMDbP5MHa817Mzjy/ajDx/A7NkwbFhZxZtKSUFE2p66unBinT079N6W0Yl26lQYNCj0HUya\nBJxzDlsve3vtQm9LloQxqGVISUFE2p5zzgkn1lT5nmgLfKWxdGkoTbHbbjBvHjzySOhY5oMPMr8h\n2/MlpnkKItL2tPZE23il0ZhYGq80AGprWxTS4YeHWkW//CVcfjlsskn0Qp8+Yf/p+vRp0XGSpisF\nEWl7sp1Q455oC3GlASxcuKaA3e9/D888A2PHpiQEgDFjoEuXtd/YpUt4vgwpKYhI29PaE20BmnSe\neCIMM73wwvD4u9+F/ffPsGFtLdx6K1RXh0kJ1dXhcQuvSJKmpCAibU9rT7TZrig6dGi2j2H+fDju\nuFC4rmtXOPTQmPHOmhWGI82aVbYJAZQURKStas2JNtOVBoSZZjlGM02aFArY3XsvnHcevPYa7L57\nq76LsqOkICKVpbEk6ZIlUFUVnmv8mipDH0PPnvCtb4VkMHo0rL9+EeItssSTgplVmdnrZjYhw2sn\nmNk8M5sW3X6ZdDwiUsFS5zdAuDLo0iV8zcBnf8Btt8GIaNWXHXaAF18MhezyPm6ZTrRLV4whqb8F\nZgJfy/L6fe7+6yLEISKVLtuoo6qqdRLDv9mKkza4h+dOCqugLV0a6hXlXcAugeGvSUr0SsHMegEH\nA7cleRwRkViyjS5qvGIAVtOBqxnFDszgnwzmllvCYjgtLmBXoOGvxZJ089E1wBlAQ45tjjSz6Wb2\noJn1TjgeEalk2UYdNY5e6taN+XRnNOezf6cXefvSxxg2LLT6tFgbm9GcWFIws0OAue4+NcdmjwE1\n7r4T8AxwV5Z9DTOzejOrnzdvXgLRikhFyDK/YcXoS7jjb1vTsGQZmzOXaQxg/MoD6HX2ca1v/2/t\nRLsiS/JKYU/gUDObBdwL7Gdm41I3cPcF7r48ejgWGJhpR+5+q7sPcvdBPXr0SDBkEWkX6uqge/fQ\nAWAW7tfVZZzf8M8zH2TgFcfyi7F78MzSsEByDbNDAbtCNPO0sRnNuHviN2AfYEKG53um3D8CeKW5\nfQ0cONBFRLIaN869Uyf3MONgzW299cJrkcWL3U8/3b1DB/ctt3Qfzw/XfQ+4m8U/bnV12L66eq1j\n5XytSIB6j3O+jrNRa2+pSQG4EDg0un8J8BbwBjAZ2K65fSkpiEhO1dWZT+4QXosMHRqeGjbM/Ysv\ncrwv5T1ZjRvn3qXL2u/r0qUkJ/9s4iYFC9u2HYMGDfL6+vpShyEi5apDh3BazuBLNmb9pV+wwQbw\nwgth0NG++0Yvpg8dhdDME6d8Rk1N5kqo1dVhtnUZMLOp7j6oue00o1lEyl8+k7+ydOBO4GC27/A2\noze/ETp0YMjPa9j345T9tKaeUhsbYZSLkoKIlLd8V1kbMwY6dWp6OI/u/JQ6fsgENmtYwI8W/in7\nflpaT6m1I4zKacZznDamcrqpT0GkwrSkrX/cOPdu3fwpvufdmeudWO6jO1/iy8nQAR2nz6A5relT\nKFJ/BDH7FHSlICLlrSVNM7W1MH8+W854mr579+D1Getx3rLfsx4rs++nNf+tx216ynSMMpvxrI5m\nESlveXTiNjTAbbfB66/DTTflsZ8xY1reyRxXto7s9ITQyCx8QwWijmaROMqpLVcyizn56733wspn\nv/oV/O//hgJ2sfdTjP/WcxXjy2SzzUrzuxmnjamcbupTkIJpA2PLJZJj8teqVe5XXOHeubP7177m\nPnase0NDnvsxy9xvEXfiWhzZjtH4e5f6uFOnMNmugL+baJ6CSDPawNhyad6nn8J228GQIXDjjbDl\nli3YSTF+F5prvjrnnNC/0acPLFoECxYUNB41H4k0px2NLa80y5fD2LGhyX3zzWHaNPjrX1uYEKA4\n9YlyHaO2Nnzt0yf8/mVKCFCU300lBalcbax6pQRTpsDAgaHP9plnwnONg35arDUT1wpxjPS5GNkU\n4XdTzUdSuVpT1kCKbvFiOPdcuOaacEVwyy1w0EGljqpAsjUtpWrl76aaj0SaU4z/DqVgDj8crr4a\nhg+Ht95qRwkBcjcLFfl3U1cKIlK2vvgC1l8/LIX54ouhZWXIkFJHlYAidHTrSkFE2rTx42H77WH0\n6PB4773baUKAslqIR0lBpBK0oUl6c+fCMcfAYYeFBdOOOqrUERVBGTVlKimIJKkcTsb5VhktoYkT\noW9feOQRuOgiqK+HQc02eLQTLa3QWmCJJwUzqzKz181sQobX1jez+8zsPTObYmY1SccjUjTlcjJu\nroRDOSSuSO/esOOOoXbRH/6wVgVsKZLEO5rN7DRgEPA1dz8k7bVTgJ3cfbiZHQMc4e4/ybU/dTRL\nm1EuM6azrURmBvfcU9JhuQ0NYWjptGnhqySnLDqazawXcDBwW5ZNDgPuiu4/COxv1qopKCLlo1xm\nTOeapFfCss3vvgv77AOnnALvvw/LliV+SIkh6eaja4AzgGz1X7cEPgRw91XAl0C3hGMSKY5ymTGd\na2RLCRLXqlVw6aWw007w5pvwpz/BU0/BBhskdkjJQ2JJwcwOAea6+9Rcm2V4bp3rXDMbZmb1ZlY/\nb968gsUokqhMJ2MIxc6K2W6fa2RLCRLXggUhKRx0ELz9NpxwQitLVEhhxSml2pIbcAkwB5gF/AdY\nAoxL2+YpYI/ofkdgPlE/R7abSmdLmxItC5mxVHI5lOguUvnwZcvcb77ZffXq8PiDDwq6e4mBUi/H\n6e5nu3svd68BjgGec/efpW02Hjg+un9UtE3bmmItkkttLWy00brPl3C5xbUUYXz8yy/DzjuH8hTP\nPRee6927YLvPXxmNtipHHYt9QDO7kJCxxgO3A/eY2XvAZ4TkIdK+lEuHcza1tYmMNFq0KAwrve66\nkAQmToShQwt+mPykF0FsHCYMqnkVUe0jkaSVy9DUIhs6FJ59Fn79a/jjH6Fr11JHRMX+LKBMhqSK\nCGVV16ZZrWxa+fzzNWsjX3BBKGJ3/fVlkhCg/K/ayoCSgkjSyqiuTU6tnIH98MPQr19IBgB77RVu\nZSXbqKoOHdTHEFHzkYgELWxa+c9/QhPRQw/BgAFwxx2hY7ksZVpYKV07XWhJzUcikp8WNK08+WS4\nOpgwIfQbvPpqGScEWPeqrapq3W3KZWRYiSgpiEjQgols1dUhCUybBmef3UYK2KVWI23IUmyhgvsY\nlBRE2rN8Oo5jdIg3NMANN8BJJ4XH/fqFEUbbbVfwyIujXEqRlBElBZH2Kt+O42Y6xP/3f8PKZ7/5\nDXz4YTspYNeWRoYVSbNJwcy+ZWbPmtmM6PFOZvaH5EMTkVZpSQXUDAu9rFwJl1wC/fuHWkV33hn6\nEtpFAbu2MjKsiOJcKYwFzgZWArj7dDTzWKT1ki63UKAx+Z9/DpdfDj/8YUgKxx/fzgrYlcmKZ+Ui\nTlLo4u6vpj23KolgRCpGMVZla0V7+bJlcOON4Tz59a/D9OnwwAOwxRaFC0/KU5ykMN/MtiEqaW1m\nRwGfJBqVSHuS6YqgGIvbtLC9/O9/D01FI0asKWDXq1fhwpLyFicpjABuAbYzs4+AUcDwRKMSaS+y\nXRFkmiQGhR0KmWd7+VdfhUloe+8NK1bA00+XQQE7KbqcM5rNrANwlLvfb2YbAh3c/auiRZeBZjRL\nm5JtlnBVFaxeve7zJSzMtv/+MHkyjBwJF1+cueK3tF1xZzTnLJ3t7g1m9mvgfndfXLDoRCpFtv/8\nV68OTTmpTUglGAr52WdhFFGXLnDRReGCYo89ihqClJk4zUeTzOy/zay3mW3WeEs8MpH2IFunbmNT\nTgmHQj74IPTtu6aA3Xe+o4Qg8RbZ+a/o64iU5xzYuvDhiLQzY8asW4Ct8YogocVtmvPJJ6ET+ZFH\nYODAih+BKWmavVJw960y3JpNCGa2gZm9amZvmNlbZjY6wzYnmNk8M5sW3X7Z0m9EpCyV2eSoxx8P\npSmefBIuvRReeSWMNBJpFGdGcyczG2lmD0a3X5tZnLJXy4H93L0/MAA4wMx2z7Ddfe4+ILrdlmf8\nIuUh10S0MpoctfXWsOuu8MYbcMYZ0LHoC/JKuYvzK3ET0Am4MXp8XPRczv/qPQxrWhQ97BTd2tbi\nDSJxlPG6v6tXhwJ206fD7beHPoSnny5pSFLm4nQ07+rux7v7c9HtRGDXODs3syozmwbMBSa5+5QM\nmx1pZtOjq5DeWfYzzMzqzax+3rx5cQ4tUjzFmIjWAm+/HeYcjBoVFsJpFwXsJHFxksLqaEYzAGa2\nNZBhgPW63H21uw8AegGDzWyHtE0eA2rcfSfgGeCuLPu51d0HufugHj16xDm0SPGU2bq/K1aEeQY7\n7wzvvgvjxoVFcNpFATtJXJyk8Dtgspk9b2Z/A54DTs/nIO7+BfA8cEDa8wvcfXn0cCwwMJ/9ipSF\nMqvJ/8UXcPXVcMQR4WqhtradFbCTRMUZffQssC0wMrp9290nN/c+M+thZptE9zsDQ4F30rbpmfLw\nUGBm/NBFykQZ1ORfujT0HTQWsHvzTbj33nBfJB9xRh+NADq7+3R3fwPoYmanxNh3T8IVxnTgn4Q+\nhQlmdqGZHRptMzIarvoGIeGc0LJvQ6SESjzs9IUXwrDS3/wmlKkA+MY3inJoaYdy1j4CMLNpUb9A\n6nOvu3tJludW7SORYOFCOOssuOkm2GorGDs21C8SyaQgtY8iHczMoiGmmFkVsF5rAxSR1jn8cHj+\neTj11FC3aMMNSx2RtAdxOpqfAu43s/3NbD/gL8DEZMMSKZGkV0Nrpfnz14x+HTMGXnoJrrpKCUEK\nJ05SOBN4FjiZUP/oWeCMJIMSKYlirIaWeqw8ko976Dju2xfOPz88t8cesHumGgEirdBsn0LThmbr\nAdsDH7n73ESjykF9CpKYbGsfdOsW/kUvlPQZ0BBGK2XpnP7oIzjlFBg/PpSouP122HHHwoUjlSFu\nn0LWKwUzu9nMto/ubwxMA+4GXjezYwsWqUi5yDbZbMGC/K4WmrsKyGMG9IQJoYDdpElwxRXw8stp\nCaHMm7uk7cnVfLS3u78V3T8ReNfddyRMMFPzkbQ/uSabxS1ZEacJKo8Z0N/8ZljnYPpFj3L69TVU\ndUo5+RezuUsqRtbmo9Rhp2b2OPCAu9+Z/lqxqflIElNXBz/7WebXzMLMsOZka4JKXWYzxzar/zWL\n664LVUzvvDMlrkzNTWawOMOCiCVc0lPKV6ubj4AvzOwQM9sZ2JNoxJGZdQQ6FyZMkTJSWxv6DzKJ\nW7IizlVAlhnQb518A3vuCaedFrowmgrYZWtuypQQcsUgEkOupPAr4NfAn4BR7v6f6Pn9gceTDkyk\nJK69tnUlK+LUQUqbAb2izze58MCX2PncQ/jXv+DPf4bHHkspYJfvSb5ENZeknXD3NnUbOHCgiyRq\n3Dj36mp3s/B13Lj83tuli3to5Q+3Ll1y7uPTT927dXP/6U/d587NsEF19dr7a+6WT7xSMYB6j3GO\njTNPQaSyNLdSWnOrrMWog7RkSbgoWb16TQG7ujrIWBk+U3NTtrKn3bqVfGEfaduUFETyEWfETzNJ\nZfLkMKx01KhQpgKgZ0+yy5Rohg/P3Mx17bUF+CalkikpiOSjFausffkl/OpXsN9+4dw+eXIeBezS\nE82NN5a0Mqu0X7mGpJ6W643uflUiETVDQ1KlpDp0CFcI6WIMWd1331Dm+vTT4YIL1v1HXyRJhaiS\n2jX6+m3Cmszjo8c/BF5oXXgibVSfPpnnGHToEJqQ0v5TnzcvFKvr0gUuuQSqqkKpCpFylbX5yN1H\nu/tooDuwi7uf7u6nE2Y092pux2a2gZm9amZvRAvpjM6wzfpmdp+ZvWdmU8yspuXfikgRZOr0hdBj\nnNK34B6Glvbdehnn97wFOnRg92Nq2PVdzTYuGZUEiSVOn0IfYEXK4xVATYz3LQf2c/f+wADgADNL\nr+n4C+Bzd/8mcDVwaYz9ipROY6dvVdW6r0V9C3PmwKGHhk2/uWQ6Jyy8TmUoSk0lQWKLkxTuAV41\nswvM7HxgCqEwXk7R0NhF0cNO0S29MfYw4K7o/oPA/mZaYlzKXG1t1v6D8bP7068fPPccXL3phfyj\nYQ+25+01G8TslJYCa8UAgUrTbFJw9zGEgnifA18AJ7r7H+Ps3MyqzGwaMJewRvOUtE22BD6MjrMK\n+BLIUmdApAAK1YSQZdbwt76xiL32CvMORn1xAVVkSB4qQ1F8eRQhrHRxh6R2ARa6+7XAHDPbKs6b\n3H21h/WdewGDzWyHtE0yXRWsM7TDzIaZWb2Z1c+bNy9myCJpCtmEEPUtrKKKKzidn3MXdOnCdpf9\nF088AVtvTbySF1Ic+lnE1mxSiJqMzgTOjp7qBIzL5yDu/gXwPHBA2ktzgN7RcToCGwOfZXj/re4+\nyN0H9cg45VMkhkI2IdTWMv0P97PHelP5HVewsPMWLLvhtrVHH2UpfBe7jpIUjn4WscW5UjgCOBRY\nDODuH7NmuGpWZtbDzDaJ7ncGhgLvpG02Hjg+un8U8Jxnmzgh0loFakJYvjwsiTnwvIP5YJP+3H8/\nPLL4+2xwYtraUzFLXkgR6GcRW5yksCI6UTuAmcVdIrwnMNnMpgP/JPQpTDCzC83s0Gib24FuZvYe\ncBpwVn7hi+ShQE0ICxeGCcXHHgtvvw0//nH2UkTN1lFqDQ2xzE+SP4t2JNfktUb3m9ktwCZmdhLw\nX8Btzb3J3acD6yzE4+7npdxfBvw4frgirTBmTObFamI0ISxeHP6xHDkyFK2bMQM23zzBWJuTvvBO\nY/8I6GQnrZK1zMVaG5l9D/g+oWP4KXeflHRg2ajMhbRKXV3oQ/jgg3CFMGZMsyfRZ5+Fk06C998P\n9/fbr0ix5hJnhTeRFIVYea1xR5e6+yR3/527/7e7TzIzTTKTtimPJoQvvoBf/hKGDoWOHeFvf2sm\nIRSzOUdDLCUhcfoUvpfhuQMLHYhIuTniiLBO8plnhjWThwzJsXGxZ8xqiKUkJGtSMLOTzexNYDsz\nm55yex94s3ghihTPp5+uWfr4f/4HpkwJXzs3typ5sWfMaoilJCTXlcKfCRVRH42+Nt4Gurt6sqRd\ncYd77oF+/cJwU4DddoOBA2PuoNjNORpiKQnJOvrI3b8EvjSza4HP3P0rADPrama7ZShZIdImffBB\nWMjsySdhjz3gF79owU6yldROsjmntlZJQAouTp/CTcCilMeLo+dE2rxHH4Xttw+L31x3Hbz4IvTt\n24IdqTlH2ok4ScFSZxm7ewPx5jeIlK3G3+jttoN99gnzDn7zm8wVsWNRc460E83OUzCzhwl1ixqv\nDk4B9nX3w5MNLTPNU5DWWLUKrrwyVDEdl1cFL5G2rWDzFIDhwHeAjwgF7HYDhrUuPJHie+ON0Hl8\n1llhYNCyZaWOSKT8NNsM5O5zgWOKEItIIpYtg4svhksvhW7d4MEH4cgjSx2VSHnKmhTM7Ax3v8zM\nrifDGgfuPjLRyEQK5Kuv4JZbQvP+VVfBZpuVOiKR8pXrSmFm9FUN+NLmLFoEN98Mp54aCti9/Xb4\nKiK55Zqn8Fj09a5s24iUnbo6nj5tIsPmXsQH9GHg58+x75ihSggiMeVqPnqMDM1Gjdz90GyviZTC\nZ7c8wOkjGrhz9T18m3d4kb3Z85pp0E9DQ0XiyjX66ArgSuB9YCkwNrotAmYkH5pIfo74bR/uWX0s\nv2cM0xjAnryUbP0hkXYoV/PR3wDM7CJ3T60P+ZiZvdDcjs2sN3A3sAXQANzq7tembbMPobbS+9FT\nD7v7hXl9B1LR/vMf6NoVNtwQLl8+kvVYzgDeWHsjlZMWiS3OPIUeZrZ14wMz2wqI00K7Cjjd3fsC\nuwMjzKxfhu1edPcB0U0JQWJxD2Wt+/WD86K1/AZXf7puQgCVkxbJQ5ykcCrwvJk9b2bPA5OBUc29\nyd0/cffXovtfEUYzbdmKWEWAsDbOAQfAiSeGukWNq1Cq/pBI68WZvDbRzLYFtoueesfdl+dzEDOr\nIazXnKmy6h5m9gbwMfDf7v5WPvuWyvLII3DccaG80A03wMknh4XOgDWdyXkutykiazSbFMysC3Aa\nUO3uJ5nZtmb2bXefEOcAZrYR8BAwyt0Xpr38WrTfRWZ2EPBXYNsM+xhGVFqjj5oCKpJ7SATbbx+W\nx7z22lBzbh0qJy3SKnEK4t0HTAV+7u47mFln4GV3H9Dszs06AROAp9z9qhjbzwIGufv8bNuoIF5l\nWbkSLr88VDH9859LHY1I21XIgnjbuPtlwEoAd18KWIwADLgdmJktIZjZFtF2mNngKJ4FMWKSCvDa\nazB4cGgNWr0alufVaCkiLRFnXYQV0dWBA5jZNkCcP889geOAN81sWvTc74E+AO5+M3AUcLKZrSLM\nhTjGm7t0kXZv6VK48MJwhdCjR+hHOLwkhdpFKk+cpHA+MBHobWZ1hJP9Cc29yd3/TjNXFO5+A3BD\njBikgixeDLffDscfD1dcAZtuWuqIRCpHzqQQNe28A/yIMNfAgN/mavMXaYmvvoKbboLTT4fu3UMB\nu+7dSx2VSOXJmRTc3c3sr+4+EHi8SDFJhZk4EX71K/jww9CHsM8+SggipRKno/kVM9s18Uik4ixY\nEJqIDjwwlKn4xz9CQhCR0onTp7AvMDwaLrqY0ITk7r5TkoFJ+/ejH8FLL8G554YRRuuvX+qIRCRO\nUjgw8SikYnzySShgt9FGoRN5vfWgf/9SRyUijbI2H5nZBmY2CvgdcADwkbvPbrwVLUJZW10d1NSE\n2g41NeFxG9i3O9xxB/Ttu6aA3a67KiGIlJtcVwp3ESasvUi4WugH/LYYQUkWdXWh+tuSJeHx7Nlr\nqsG1trRDgvv+979DR/Izz8CQITB8eOtCFZHkZC1zYWZvuvuO0f2OwKvuvksxg8ukostc1NSEk3W6\n6upQOrQM9/3ww6GAXVUVXHZZyDMd4gxvEJGCilvmIteVwsrGO+6+KqpGIaWUbbGYQiwiU+B9Nxaw\n23HHUOb6mmugd+9WxCciRZHrf7b+ZrYwun0F7NR438zSq51KMWSrEFuIyrEF2veKFXDxxfDTn4bE\nsO228NBDSggibUXWpODuVe7+tejW1d07ptz/WjGDlEiSi8gUYN/19aHz+Nxzw+MVK1oflogUl1p3\n25LaWrj11tDObxa+3nprYdYPaMW+ly6FM86A3XaD+fPh0UfhL3/RvAORtkhJoTWSHB6aTW1t6Pht\naAhfW5IQssXdwn0vXhzWS/7FL+Ctt+DQQ/MPSUTKQ5zJa5JJksNDk1SguBcuhBtvhN/9LtQpmjkT\nunVLIF4RKapmV14rN2UzJDXJ4aFJKkDcjz8e5hp8/DE8+6zqFYm0BYVceU0ySXJ4aJJaEfe8eeFi\n4pBDYOONQ90iJQSR9iWxpGBmvc1sspnNNLO3zGyd2dAWXGdm75nZdDMr+eS42JIcHpqkVsR95JHw\nwANwwQVhqczdditsaCJSekleKawCTnf3voQFekaYWb+0bQ4Eto1uw4CbEoynsJIcHhpHSzu584z7\no49g0aJw/+qrQzI4//xQyE5E2p/EkoK7f+Lur0X3vwJmAlumbXYYcLcHrwCbmFnPpGIqqCSHhzan\nsbN49uwwQ6yxszhOYogZtzuMHQv9+q0pYDdwIOywQwLfj4iUjaJ0NJtZDfACsIO7L0x5fgLwP9F6\nzpjZs8CZ7l6f9v5hhCsJ+vTpM3B2po7SSpJwJ/e//gUnnQSTJ8O++4bksM02rd6tiJRQ2XQ0m9lG\nwEPAqNSE0Phyhresk6Xc/VZ3H+Tug3r06JFEmG1Lgp3cDz4Y6hVNnRouIJ59VglBpJIkmhTMrBMh\nIdS5+8MZNpkDpFbF6QV8nGSl8MHwAAAP+UlEQVRM7UICndyNF4z9+8PBB4dJaCedFFqYRKRyJDn6\nyIDbgZnuflWWzcYDP49GIe0OfOnunyQVU7tRwE7uFStg9Gg45pg1BeweeAB69SpQrCLSpiR5pbAn\ncBywn5lNi24HmdlwM2tcZuUJ4N/Ae8BY4JQE42k/CtTJ/eqrofP4ggugY0cVsBMRzWiuSEuWhBFF\nV18NPXvCzTeHCWki0n6VTUezlJ+lS2HcuDCK9e23lRBEZA0VxKsQX34JN9wAZ54ZCtfNnAmbblrq\nqESk3OhKIUmlKK2dwWOPrZmE9ve/h+eUEEQkEyWFpLRm1nGBzJsHxx4b1jfo1g2mTFEBOxHJTUkh\nKeecs2bNgkZLloTni+TII8P6yBdeGJbKHNRsF5OIVDolhaSUqLT2nDlrCthdcw28ftEEzr29hvU2\nKG0Tloi0DUoKSSnkrOMYfRMNDXDLLaHv4Nxzw3O7zKxj+wt/UtImLBFpW5QUklKoWccx+ib+7/9g\nv/3CamiDB8NvfhO9UAZNWCLStigpJKVQpbWbObE/8ADstBNMmwa33w6TJsHWW0fbtdXV4USkZDRP\nIUm1ta1fXyHLCdxnf4ABO+8Mhx0GV10F3/hG2kZ9+mQusV3uq8OJSMnoSiFfxZ57kHYCX856nMdo\nju7yGO7wzW/CvfdGCSE9toMOKu3qcCLS5igp5CPu3INCJo6UvolX2I1deI2LOI/Ou/Rdu4Bdptju\nugv22AOqqsI2VVVw/PHFWR2uEpTJ5ESRgnL3NnUbOHCgF8S4ce7V1e5m4eu4cc2/p1s393DKXftW\nXb32frt0Wfv1Ll3i7T+LRbf9xUd1vc2N1d67ao4/8bvn1t2oujpzbGYFjUUiCfycRZIE1HuMc2zJ\nT/L53gqSFFryBz1uXOaTbuOJt1G2k3O3bmv2k2cymj/ffYst3EeMcF+4MENc2Y6Z7ZaaxKRlsn3m\n+mylTCkp5NKSP+hcJ97U9+U6GZ98cuxk9Pkt9/mFG1/hK+noXl3tn99y35oXUxNB+pVAnFtqEpOW\nyfa567OVMhU3KVTmegodOqxZfzKVWZgFls97INShbmyn79gRVq/OvF1VVebXqqth1qymh3899W+c\ncu23mOs9eI79GMKLoV/h1lvDBsOGrTtMNROzzDFXVYX+BvUttFxNTeaRXWk/S5FyUfL1FMzsDjOb\na2Yzsry+j5l9mbIq23lJxbKOlsw2zvZat25rn1yzJYRcr0XDTj/9FI4+Go645rt83T9lCruFhABr\n5iZkmreQSXV1mM2WPvqoMQ7NbG6dAi6JKlJW4lxOtOQGDAF2AWZkeX0fYEK++y1pn0Kc9+RqZqqq\nytn8tNde7uut534x5/gKOubfLJSt47uZ40oLtWSwgkiJUA59CkBNWSYF95b9Qcd5z7hx4cyefgLu\n1Cljn8LsDb7lC8fe6+7ur73m/tZbHn8kUaZbpkSl9m+RitdWksIC4A3gSWD7HPsZBtQD9X369Eno\nIyugcePWHr7arduaE3WUWFbTwW/Y7A++0QYrfNSoDO9PvyrJlRAaX8uWqLIlmaoq/XcrUiHaQlL4\nGrBRdP8g4P/i7LNgVwol9M5lj/pe609xcP9eh2f8fdtqzUn65JPDRulXJbmuDpo7sWdKMnGbzUSk\nXYibFEo2o9ndF7r7ouj+E0AnM+teqngSF81+vd+Opv8Z32fG8m35EyfwVMNQavz9sM3q1XDTTXDK\nKaHzetasMBpq1qzQcZxJdXXzo4gai/M1zmxOpaqpIpKiZEnBzLYwM4vuD45iWVCqeBJVV4efFEpQ\nDGQqP+JhZtKXE7gLy7R949DTVK0d7VJbm324raqmikgkySGpfwFeBr5tZnPM7BdmNtzMhkebHAXM\nMLM3gOuAY6JLnHZl2TI455TPOWrp3TiwDf/mz9SyBZ9mf1OmoastLcWdWp+nQ5Yft6qmikijOG1M\n5XQrSp9CgYYa/uMf7tttF5ruj+dPvowMo5KydQAX6vvI1pegPgWRikK59ymUrbiVUHNYtAhGjoS9\n9gpN9hO//nPu5ETWZ0Xzb4ZwvELINtGtqqp1C/+ISLulpJCuAEtYrlgBDz4II0bAjBnwg6t+sG5/\ngEW9CRtuuKZZp6oKTj4ZbryxFd9Aimx9BQ0NazqwlRBEJIWSQroWLmH52WdwwQWwahVsthnMnAnX\nXw9du5K5P+Cee8KVyKJFoQ/BPby5UAkBWlbOQ0QqmpJCuhacSB96CPr1g4svhpdeCs9tvHECseVL\n9XlEJE9KCunyOJF+8gkceSQcdVRYDrO+HoYMybDPAvRTtEhLRyyJSMWqzNLZzamrC30IH3wQrhDG\njMl4It17b/jnP2H0aDj99FA1OyOVWRaREotbOltJIU+zZ4c+g65dYdo06NwZvv3tZt7UkvUbREQK\nqOTrKbQ3DQ2h43j77eHcc8NzAwbESAigDl8RaTOUFGJ4553QVzByZGgyOvXUPHegDl8RaSOUFJpx\n773Qv38YYnr33fDEE9lr02WlDl8RaSOydY1WvIaG0BWw667w4x/DlVfC5pu3Yoe1tUoCIlL2dKWQ\nZulSOOusMNTUHbbZBsaNa2VCEBFpI5QUUrz4Yug8vvRS6NYNVq4sdUQiIsWlpAB89VWoUzRkSEgE\nkybBbbfBeuuVOjIRkeJSUiAkgr/+FUaNgjffhKFDSx2RiEhpJLnIzh1mNtfMZmR53czsOjN7z8ym\nm9kuScWSyYIFcN55awrYvfMOXH11KFoqIlKpkrxSuBM4IMfrBwLbRrdhwE0JxtLEHR54IBSwu+QS\nePnl8HzXrsU4uohIeUssKbj7C8BnOTY5DLg7WhToFWATM+uZVDwAH38MP/oRHH009O4dCtjtvXeS\nRxQRaVtK2aewJfBhyuM50XOJOfpomDgRLrsMXnklTEoTEZE1Sjl5zTI8l7E6n5kNIzQx0acV9YL+\n3/8LBey+9a0W70JEpF0r5ZXCHKB3yuNewMeZNnT3W919kLsP6tGjR4sP2L+/EoKISC6lTArjgZ9H\no5B2B750909KGI+ISMVLrPnIzP4C7AN0N7M5wPlAJwB3vxl4AjgIeA9YApyYVCwiIhJPYknB3Y9t\n5nUHRiR1fBERyZ9mNIuISBMlBRERaaKkICIiTZQURESkiZKCiIg0sTAIqO0ws3nA7Ba+vTswv4Dh\nFEq5xgXlG5viyo/iyk97jKva3Zud/dvmkkJrmFm9uw8qdRzpyjUuKN/YFFd+FFd+KjkuNR+JiEgT\nJQUREWlSaUnh1lIHkEW5xgXlG5viyo/iyk/FxlVRfQoiIpJbpV0piIhIDu0yKZjZHWY218xmZHnd\nzOw6M3vPzKab2S5lEtc+ZvalmU2LbucVIabeZjbZzGaa2Vtm9tsM2xT984oZVyk+rw3M7FUzeyOK\na3SGbdY3s/uiz2uKmdWUSVwnmNm8lM/rl0nHlXLsKjN73cwmZHit6J9XzLhK+XnNMrM3o+PWZ3g9\nub9Jd293N2AIsAswI8vrBwFPElZ/2x2YUiZx7QNMKPJn1RPYJbrfFXgX6FfqzytmXKX4vAzYKLrf\nCZgC7J62zSnAzdH9Y4D7yiSuE4Abivl5pRz7NODPmX5epfi8YsZVys9rFtA9x+uJ/U22yysFd38B\n+CzHJocBd3vwCrCJmfUsg7iKzt0/cffXovtfATNZd63son9eMeMquugzWBQ97BTd0jvmDgPuiu4/\nCOxvZpmWny12XCVhZr2Ag4HbsmxS9M8rZlzlLLG/yXaZFGLYEvgw5fEcyuCEE9kjagJ40sy2L+aB\no8v2nQn/ZaYq6eeVIy4owecVNTlMA+YCk9w96+fl7quAL4FuZRAXwJFRc8ODZtY7w+tJuAY4A2jI\n8npJPq8YcUFpPi8ICf1pM5tqYY36dIn9TVZqUsj0X0g5/Ff1GmEqen/geuCvxTqwmW0EPASMcveF\n6S9neEtRPq9m4irJ5+Xuq919AGFd8cFmtkPaJiX5vGLE9RhQ4+47Ac+w5r/zxJjZIcBcd5+aa7MM\nzyX6ecWMq+ifV4o93X0X4EBghJkNSXs9sc+sUpPCHCA16/cCPi5RLE3cfWFjE4C7PwF0MrPuSR/X\nzDoRTrx17v5whk1K8nk1F1epPq+U438BPA8ckPZS0+dlZh2BjSlis2G2uNx9gbsvjx6OBQYWIZw9\ngUPNbBZwL7CfmY1L26YUn1ezcZXo82o89sfR17nAI8DgtE0S+5us1KQwHvh51IO/O/Clu39S6qDM\nbIvGtlQzG0z4+SxI+JgG3A7MdPersmxW9M8rTlwl+rx6mNkm0f3OwFDgnbTNxgPHR/ePAp7zqHew\nlHGltTkfSuinSZS7n+3uvdy9htCJ/Jy7/yxts6J/XnHiKsXnFR13QzPr2ngf+D6QPmIxsb/JxNZo\nLiUz+wthZEp3M5sDnE/oeMPdbwaeIPTevwcsAU4sk7iOAk42s1XAUuCYpP84CP8xHQe8GbVHA/we\n6JMSVyk+rzhxleLz6gncZWZVhCR0v7tPMLMLgXp3H09IZveY2XuE/3iPSTimuHGNNLNDgVVRXCcU\nIa6MyuDzihNXqT6vzYFHov93OgJ/dveJZjYckv+b1IxmERFpUqnNRyIikoGSgoiINFFSEBGRJkoK\nIiLSRElBRESatMshqSKpzKwb8Gz0cAtgNTAvejzY3VcU6DgbEerobE+Ycfo58AN3X1KI/YsUg4ak\nSkUxswuARe5+RdrzRvh7yFUHp7l9nwt0dfczosfbAf9y95Wt2GfHqB6QSFGo+Ugqlpl908xmmNnN\nhDpKvc3si5TXjzGz26L7m5vZw2ZWb2Hdgt0z7LIn8FHjA3d/pzEhmNmJUWG1N8zsT9FzW1lYM2K6\nmU2KqnZiZuPM7Eozmwz80cw2MrM7o+O+bmY/TOxDkYqn5iOpdP2AE919eFR3J5vrgMvc/RULVVsn\nAOkF524HJprZTwjNVXe5+3tm1h84E/iOu39mZptF298I3ObudVElzGsIs7QBtgH2d/cGM7sMmOju\nJ5jZpsAUM5vk7sta/d2LpFFSkEr3L3f/Z4zthgLftjVl/jc1s87uvrTxCXefamZbE2rVDAXqo5pM\n+xEWjvks2q6x2NtuwCHR/buBi1KO90BKU9b3gQPN7Kzo8QaEch/v5vF9isSipCCVbnHK/QbWLkm8\nQcp9I0andLQg0EPAQ1E/xYHRe/PtvEuNy4DD3f1fee5DJG/qUxCJRP+Zf25m25pZB+CIlJefAUY0\nPjCzAenvN7O9UiqVrg/0BWZH7z2msdkopfnoFeDo6P7PgBeyhPYUMDLlODvn/92JxKOkILK2M4GJ\nhD6BOSnPjwD2jDqF3wZOyvDebYEXzexNQsf1y8Cj7j4duAx4Iar4enm0/a+BYWY2HfgJcGqWmEYD\nXSws5P4WcEFrvkGRXDQkVUREmuhKQUREmigpiIhIEyUFERFpoqQgIiJNlBRERKSJkoKIiDRRUhAR\nkSZKCiIi0uT/AyPJzWXftxYiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = best_regressors_mae['Random Forest'].fit(X_train[6], y_train[6]).predict(X_test[6])\n",
    "plt.scatter(y_test[6], y_pred, color = 'r')\n",
    "plt.plot([1, 5], [1, 5], color='b', linestyle='dashed')\n",
    "plt.xlabel('True Score')\n",
    "plt.ylabel('Predicted Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p1 = plt.bar(np.arange(len(features)), best_regressors_mse['AdaBoost'].feature_importances_, width = -0.4, align = 'edge')\n",
    "p2 = plt.bar(np.arange(len(features)), best_regressors_mse['Random Forest'].feature_importances_, width = 0.4, align = 'edge')\n",
    "plt.xticks(np.arange(len(features)), tuple(features))\n",
    "plt.ylabel('Feature Importance')\n",
    "plt.legend((p1, p2), ('AdaBoost', 'Random Forest'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-22-7d6fcad587a1>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-7d6fcad587a1>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    x[...] = 0 if x != 1\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def get_roc(y_label_true, y_score, class_name):\n",
    "    for x in np.nditer(y_label_true, op_flags=['readwrite']):\n",
    "        if class_name == 'Bad':\n",
    "            x[...] = 1 if x > 0 else 0\n",
    "        elif class_name == 'Good':\n",
    "            x[...] = 0 if x < 2 else 1\n",
    "        elif class_name == 'Average':\n",
    "            x[...] = 0 if x != 1 else \n",
    "        else:\n",
    "            print(\"invalid class name\")\n",
    "    fpr, tpr, _ = roc_curve(y_label_true, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    return (fpr, tpr, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names = ['Good', 'Bad', 'Average']\n",
    "roc_data = {}\n",
    "for cn in class_names:\n",
    "    roc_data[cn] = {}\n",
    "    for k, v in best_regressors_mse.items():\n",
    "        roc_data[cn][k] = []\n",
    "        for i in range(num_splits):\n",
    "            y_score = v.fit(X_train[i], y_train[i]).predict(X_test[i])\n",
    "            y_label_true = to_label(y_test[i], thresh_scores_mse[k][i][0])  \n",
    "            roc_data[cn][k].append(get_roc(y_label_true, y_score, cn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cn, v in roc_auc.items():\n",
    "    print(\"Average ROC AUC for '{}'\".format(cn))\n",
    "    for k, v1 in v.items():\n",
    "        print(k)\n",
    "        print(np.around(np.average(v1), decimals = 3))\n",
    "    print(\"##################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 6  # pick 6th split (you can pick any one)\n",
    "reg_names = ['Random Forest', 'AdaBoost']\n",
    "for rn in reg_names:\n",
    "    plt.figure()\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.05])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    for cn, v in roc_data.items(): \n",
    "        plt.plot(v[rn][i][0], v[rn][i][1])\n",
    "    plt.legend([''] + ['Class {}, area = {:.2f}'.format(cn, roc_data[cn][rn][i][2]) for cn in roc_data])\n",
    "    plt.title('Receiver operating characteristic: {}'.format(rn))\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    #plt.legend(plots, roc_data.keys(), loc = 'lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_meshgrid(x, y, h=.02):\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "def plot_contours(reg_name, xx, yy, **params):\n",
    "    Z = best_regressors_mae[reg_name].predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = to_label(Z, thresh_accuracy_mae[reg_name][0])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = plt.contourf(xx, yy, Z, **params)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = ['red', 'green', 'blue']\n",
    "cmap = mpl.colors.ListedColormap(colors)\n",
    "rg = np.arange(0, 1.01, 0.01)\n",
    "x1, x2, lb = np.array(df_reg['BitRate']), np.array(df_reg['FreezeRatio']), np.array(df_reg['Quality'])\n",
    "xx1, xx2 = make_meshgrid(rg, rg)\n",
    "for reg, name in zip(list(best_regressors_mae.values()), list(best_regressors_mae.keys())):\n",
    "    plot_contours(name, xx1, xx2, cmap=cmap, alpha=0.8)\n",
    "    plt.scatter(x1, x2, c = lb, cmap=cmap, s=20, edgecolors='k')\n",
    "    plt.xlim(rg.min(), rg.max())\n",
    "    plt.ylim(rg.min(), rg.max())\n",
    "    plt.xlabel('Bit Rate')\n",
    "    plt.ylabel('Freeze Ratio')\n",
    "    plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.title(name)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
